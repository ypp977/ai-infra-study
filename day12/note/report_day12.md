# Day12 - TensorRT Plugin å…¥é—¨

------

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- ç†è§£ä¸ºä»€ä¹ˆ/ä½•æ—¶éœ€è¦è‡ªå®šä¹‰ TensorRT Plugin
- å­¦ä¹  **IPluginV2 / IPluginV2DynamicExt** çš„æ¥å£ä¸ç”Ÿå‘½å‘¨æœŸ
- å®ç°ä¸€ä¸ªç®€å•çš„ **æ¿€æ´»å‡½æ•° Pluginï¼ˆå¦‚ ReLU/Swishï¼‰**
- æŒæ¡ Plugin çš„åºåˆ—åŒ–/ååºåˆ—åŒ–ã€è¾“å…¥è¾“å‡º shape æ¨æ–­ã€workspace ç®¡ç†
- å°† Plugin é›†æˆåˆ° TensorRT Engine å¹¶è¿è¡Œæ¨ç†

------

## 1ï¸âƒ£ ä»£ç å®éªŒï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰

### æ€è·¯è®²è§£

åœ¨ TensorRT ä¸­ï¼Œå¤§éƒ¨åˆ†å¸¸è§ç®—å­ï¼ˆå·ç§¯ã€GEMMã€æ¿€æ´»ï¼‰éƒ½æœ‰å†…ç½®æ”¯æŒã€‚ä½†åœ¨ä»¥ä¸‹åœºæ™¯ä¸­éœ€è¦è‡ªå®šä¹‰ **Plugin**ï¼š

- **æ¡†æ¶ä¸­æœ‰è€Œ TensorRT æ²¡æœ‰çš„ç®—å­**ï¼ˆå¦‚ Swishã€Mishã€LayerNorm çš„æŸäº›å˜ä½“ï¼‰
- **éœ€è¦ç‰¹æ®Šä¼˜åŒ–**ï¼ˆèåˆç®—å­ã€å‡å°‘è®¿å­˜ã€é¿å…å†—ä½™ kernelï¼‰
- **ç ”ç©¶æ€§/å®éªŒæ€§ç®—å­**ï¼ˆå¿«é€ŸéªŒè¯æ–°ç»“æ„ï¼‰

å®éªŒç›®æ ‡ï¼š

1. ç¼–å†™ä¸€ä¸ª **Swish Plugin**ï¼ˆSwish(x) = x * sigmoid(x)ï¼‰ã€‚
2. æ”¯æŒ **åŠ¨æ€ shape**ï¼ˆä½¿ç”¨ `IPluginV2DynamicExt`ï¼‰ã€‚
3. é›†æˆåˆ° TensorRT æ„å»ºæµç¨‹ä¸­ï¼Œå¹¶å¯¹æ¯” TensorRT å†…ç½® ReLUã€‚

------

### Plugin å®ç°æ ¸å¿ƒä»£ç 

#### my_swish_plugin.h

```c++
#ifndef MY_WISH_PLUGIN_H
#define MY_WISH_PLUGIN_H

#include "NvInfer.h"
#include <cassert>
#include <cmath>
#include <string>
#include <vector>

using namespace nvinfer1;

class SwishPlugin : public IPluginV2DynamicExt
{
  public:
    SwishPlugin() {}
    SwishPlugin(const void* data, size_t length) {}

    // 1. è·å–æ’ä»¶ç±»å‹
    const char* getPluginType() const noexcept override
    {
        return "SwishPlugin";
    }

    // 2. è·å–æ’ä»¶ç‰ˆæœ¬
    const char* getPluginVersion() const noexcept override
    {
        return "1";
    }

    // 3. è·å–è¾“å‡ºæ•°é‡
    int getNbOutputs() const noexcept override
    {
        return 1;
    }

    // 4. è·å–è¾“å‡ºç»´åº¦
    DimsExprs getOutputDimensions(int outputIndex, const DimsExprs* inputs, int nbInputs,
                                  IExprBuilder& exprBulider) noexcept override
    {
        return inputs[0]; // è¾“å…¥ç»´åº¦ä¸è¾“å‡ºç›¸åŒ
    }

    // 5. æ”¯æŒçš„ç»„åˆ
    bool supportsFormatCombination(int pos, const PluginTensorDesc* inOut, int nbInputs,
                                   int nbOutputs) noexcept override
    {
        return inOut[pos].format == TensorFormat::kLINEAR && inOut[pos].type == DataType::kFLOAT;
    }

    // 6. é…ç½®æ’ä»¶
    void configurePlugin(const DynamicPluginTensorDesc* inputs, int nbInputs,
                         const DynamicPluginTensorDesc* outputs, int nbOutputs) noexcept override
    {
    }

    // 7. è·å– workspace å¤§å°
    size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs,
                            const PluginTensorDesc* outputs, int nbOutputs) const noexcept override
    {
        return 0; // æ— éœ€é¢å¤– workspace
    }

    // 8. æ‰§è¡Œæ’ä»¶
    int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                const void* const* inputs, void* const* outputs, void* workspace,
                cudaStream_t stream) noexcept override;

    // 9. è·å–åºåˆ—åŒ–å¤§å°
    size_t getSerializationSize() const noexcept override {}

    // 10. åºåˆ—åŒ–æ’ä»¶
    void serialize(void* buffer) const noexcept override {}

    // 11. åˆå§‹åŒ–æ’ä»¶
    int initialize() noexcept override
    {
        return 0;
    }

    // 12. ç»ˆæ­¢æ’ä»¶
    void terminate() noexcept override {}

    // 13. å…‹éš†æ’ä»¶
    IPluginV2DynamicExt* clone() const noexcept override
    {
        return new SwishPlugin();
    }

    // 14. é”€æ¯æ’ä»¶
    void destroy() noexcept override
    {
        delete this;
    }

    // 15. è®¾ç½®æ’ä»¶å‘½åç©ºé—´
    void setPluginNamespace(const char* pluginNamespace) noexcept override {}

    // 16. è·å–æ’ä»¶å‘½åç©ºé—´
    const char* getPluginNamespace() const noexcept override
    {
        return "";
    }

    // 17. è·å–è¾“å‡ºæ•°æ®ç±»å‹
    DataType getOutputDataType(int index, const DataType* intputTypes,
                               int nbInputs) const noexcept override
    {
        return intputTypes[0];
    }

    // 18. ç»‘å®šåˆ°ä¸Šä¸‹æ–‡
    void attachToContext(cudnnContext*, cublasContext*, IGpuAllocator*) noexcept override {}

    // 19. ä»ä¸Šä¸‹æ–‡åˆ†ç¦»
    void detachFromContext() noexcept override {}
};

class SwishPluginCreator : public IPluginCreator
{
  public:
    // 1. è·å–æ’ä»¶åç§°
    const char* getPluginName() const noexcept override
    {
        return "SwishPlugin";
    }

    // 2. è·å–æ’ä»¶ç‰ˆæœ¬
    const char* getPluginVersion() const noexcept override
    {
        return "1";
    }

    // 3. è·å–æ’ä»¶å­—æ®µ
    const PluginFieldCollection* getFieldNames() noexcept override
    {
        return nullptr;
    }

    // 4. åˆ›å»ºæ’ä»¶
    IPluginV2* createPlugin(const char* name, const PluginFieldCollection* fc) noexcept override
    {
        return new SwishPlugin();
    }

    // 5. ååºåˆ—åŒ–æ’ä»¶
    IPluginV2* deserializePlugin(const char* name, const void* serialData,
                                 size_t serialLength) noexcept override
    {
        return new SwishPlugin(serialData, serialLength);
    }

    // 6. è®¾ç½®æ’ä»¶å‘½åç©ºé—´
    void setPluginNamespace(const char* pluginNamespace) noexcept override {}

    // 7. è·å–æ’ä»¶å‘½åç©ºé—´
    const char* getPluginNamespace() const noexcept override
    {
        return "";
    }
};
#endif

```

#### my_swish_plugin.cu

```c++
#include "my_swish_plugin.h"
#include <cuda_runtime.h>

// swish kernel
__global__ void swish_kernel(const float* input, float* output, int num)
{
    // è®¡ç®—çº¿ç¨‹ç´¢å¼•
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < num)
    {
        // è®¡ç®— swish å€¼
        float x = input[i];
        output[i] = x / (1.0f + expf(-x));
    }
}

// enqueue
int SwishPlugin::enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                         const void* const* inputs, void* const* outputs, void* workspace,
                         cudaStream_t stream) noexcept
{
    // è®¡ç®—è¾“å…¥å’Œè¾“å‡ºçš„å¤§å°
    int num = 1;

    for (int i = 0; i < inputDesc[0].dims.nbDims; i++)
    {
        num *= inputDesc[0].dims.d[i];
    }

    // è·å–è¾“å…¥å’Œè¾“å‡º
    const float* input = reinterpret_cast<const float*>(inputs[0]);
    float* output = reinterpret_cast<float*>(outputs[0]);

    // è®¡ç®— block å’Œ grid
    int block = 256;
    int grid = (num + block - 1) / block;

    // å¯åŠ¨ kernel
    swish_kernel<<<grid, block>>>(input, output, num);

    return 0;
}

```

### ç¼–è¯‘ä¸è¿è¡Œæ­¥éª¤

1. **å‡†å¤‡ TensorRT ç¯å¢ƒ**

   ```bash
   docker run --gpus all -it --rm -v $PWD:/workspace  my-ai-infer:trt bash
   ```

2. **ç¼–è¯‘ Plugin**

   ```bash
   nvcc -I/usr/include/x86_64-linux-gnu -I/usr/include -shared -Xcompiler -fPIC my_swish_plugin.cu -o libswish.so
   ```

   ![image-20250906031439534](./report_day12.assets/image-20250906031439534.png)

3. **æ„å»ºç½‘ç»œæ—¶æ³¨å†Œ Plugin**

   ```python
   import ctypes
   import numpy as np
   import tensorrt as trt
   import pycuda.driver as cuda
   import pycuda.autoinit  # è‡ªåŠ¨åˆå§‹åŒ– CUDA ä¸Šä¸‹æ–‡
   
   # 1. åŠ è½½æ’ä»¶åº“
   ctypes.CDLL("./libswish.so")
   
   # 2. åˆå§‹åŒ– TensorRT
   logger = trt.Logger(trt.Logger.INFO)
   builder = trt.Builder(logger)
   network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
   config = builder.create_builder_config()
   trt.init_libnvinfer_plugins(logger, '')
   
   # 3. è·å– SwishPlugin
   creator_list = trt.get_plugin_registry().plugin_creator_list
   swish_creator = [c for c in creator_list if c.name == "SwishPlugin"][0]
   plugin = swish_creator.create_plugin("swish_layer", trt.PluginFieldCollection([]))
   
   # 4. æ„å»ºç½‘ç»œï¼šInput â†’ Swish â†’ Output
   input_tensor = network.add_input("input", trt.DataType.FLOAT, (1, 6))
   swish_layer = network.add_plugin_v2([input_tensor], plugin)
   network.mark_output(swish_layer.get_output(0))
   
   # 5. æ„å»º Engine
   serialized_engine = builder.build_serialized_network(network, config)
   runtime = trt.Runtime(logger)
   engine = runtime.deserialize_cuda_engine(serialized_engine)
   context = engine.create_execution_context()
   print("âœ… Engine æ„å»ºæˆåŠŸ")
   
   # 6. å‡†å¤‡è¾“å…¥
   inp = np.array([[1, 2, 3, -1, -2, -3]], dtype=np.float32)
   out = np.empty_like(inp)
   
   # åˆ†é… GPU å†…å­˜
   d_input = cuda.mem_alloc(inp.nbytes)
   d_output = cuda.mem_alloc(out.nbytes)
   
   # Host â†’ Device
   cuda.memcpy_htod(d_input, inp)
   
   # åœ¨ execute_v2 ä¹‹å‰è®¾ç½® shape
   context.set_input_shape("input", (1, 6))
   
   assert context.all_binding_shapes_specified, "è¾“å…¥ shape æœªæŒ‡å®š"
   # è¿è¡Œæ¨ç†
   context.execute_v2([int(d_input), int(d_output)])
   
   # Device â†’ Host
   cuda.memcpy_dtoh(out, d_output)
   
   print("è¾“å…¥:", inp)
   print("Swish è¾“å‡º:", out)
   
   ```

4. **è¿è¡Œæ¨ç†**

   ```bash
   python test_swish_plugin.py
   ```

   è¿è¡Œç»“æœ

   ![image-20250906043056053](./report_day12.assets/image-20250906043056053.png)

------

### Nsight Compute/Systems å…³æ³¨æŒ‡æ ‡

- **Kernel Launch æ—¶é—´**ï¼ˆPlugin æ˜¯å¦é¢å¤–å¢åŠ å¼€é”€ï¼‰
- **Global memory throughput**ï¼ˆSwish ç®—å­è®¿å­˜æ˜¯å¦é«˜æ•ˆï¼‰
- **Occupancy**ï¼ˆçº¿ç¨‹å—è°ƒåº¦æ•ˆç‡ï¼‰
- **Stream overlap**ï¼ˆæ˜¯å¦èƒ½ä¸å…¶ä»–ç®—å­å¹¶è¡Œæ‰§è¡Œï¼‰

------

## 2ï¸âƒ£ æ·±åº¦è¿½é—®

1. **IPluginV2DynamicExt vs IPluginV2**
   - å‰è€…æ”¯æŒåŠ¨æ€ batch å’Œ shapeï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒï¼›åè€…ä»…é€‚åˆå›ºå®šè¾“å…¥ã€‚
2. **æ•°æ®æ ¼å¼ä¸ layout è½¬æ¢**
   - TensorRT å†…éƒ¨å¯èƒ½æ˜¯ NCHW/NHWCï¼Œè½¬æ¢éœ€è¦é¢å¤– kernelï¼Œä»£ä»·é«˜ã€‚
3. **Plugin åºåˆ—åŒ–å…¼å®¹æ€§**
   - å¿…é¡»åœ¨ `serialize/deserialize` ä¸­ä¿å­˜å‚æ•°ï¼Œå¦åˆ™è·¨è¿›ç¨‹æ— æ³•è¿˜åŸã€‚
4. **å¤šçº¿ç¨‹/å¤šå®ä¾‹å®‰å…¨æ€§**
   - Plugin å†…éƒ¨ä¸èƒ½ä½¿ç”¨å…¨å±€å˜é‡ï¼›å¿…é¡»é¿å…éçº¿ç¨‹å®‰å…¨æ“ä½œã€‚
5. **Shape æ¨æ–­**
   - åœ¨ `getOutputDimensions` ä¸­å®ç°ï¼Œé¿å…è¿è¡Œæ—¶ shape é”™è¯¯ã€‚
6. **é”™è¯¯å¤„ç†ç­–ç•¥**
   - Plugin å†…éƒ¨æŠ¥é”™ä¼šå¯¼è‡´æ•´ä¸ª engine å´©æºƒï¼Œéœ€è¦æå‰åšå‚æ•°æ£€æŸ¥ã€‚

------

## 3ï¸âƒ£ å®éªŒéƒ¨åˆ†

### ğŸ§ª å®éªŒ 1ï¼šSwish Plugin vs å†…ç½® ReLU

#### 1ï¸âƒ£ å®éªŒç›®æ ‡

- æ¯”è¾ƒ TensorRT å†…ç½® ReLU å’Œ è‡ªå®šä¹‰ Swish æ’ä»¶çš„è¿è¡Œå»¶è¿Ÿã€‚
- éªŒè¯ Swish æ’ä»¶åŠŸèƒ½æ˜¯å¦æ­£ç¡®ã€‚

------

#### 2ï¸âƒ£ å®éªŒæ–¹æ³•

1. è¾“å…¥å›ºå®šå¤§å° `(1, 1024)` çš„éšæœºæ•°æ®ã€‚
2. æ„å»ºä¸¤ä¸ª TensorRT Engineï¼š
   - **Engine A**ï¼šInput â†’ ReLU â†’ Output
   - **Engine B**ï¼šInput â†’ SwishPlugin â†’ Output
3. ä½¿ç”¨ `time.perf_counter()` å¤šæ¬¡è¿è¡Œï¼Œå–å¹³å‡å»¶è¿Ÿã€‚
4. å¯¹æ¯”ç»“æœã€‚

------

#### 3ï¸âƒ£ Python å®éªŒä»£ç 

ä¿å­˜ä¸º `experiment_relu_vs_swish.py`ï¼š

```python
import ctypes
import time
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

# åŠ è½½æ’ä»¶åº“
ctypes.CDLL("./libswish.so")

# TRT Logger
logger = trt.Logger(trt.Logger.INFO)

# é€šç”¨å‡½æ•°ï¼šæ„å»º engine
def build_engine(use_relu = True):
    # åˆ›å»º builder
    builder = trt.Builder(logger)
    # åˆ›å»ºç½‘ç»œ
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))

    # åˆ›å»ºé…ç½®
    config = builder.create_builder_config()
    # åˆå§‹åŒ–æ’ä»¶
    trt.init_libnvinfer_plugins(logger,'')

    # åˆ›å»ºè¾“å…¥
    input_tensor = network.add_input("input",trt.DataType.FLOAT,(1,1024))

    if(use_relu):
        # åˆ›å»º ReLU å±‚
        relu_layer = network.add_activation(input_tensor,trt.ActivationType.RELU)
        # æ ‡è®°è¾“å‡º
        network.mark_output(relu_layer.get_output(0))
    else:
        # è·å– Swish æ’ä»¶
        creator_list = trt.get_plugin_registry().plugin_creator_list
        swish_creator = [c for c in creator_list if c.name == "SwishPlugin"][0]
        # åˆ›å»º Swish å±‚
        plugin = swish_creator.create_plugin("swish_layer", trt.PluginFieldCollection([]))
        swish_layer = network.add_plugin_v2([input_tensor], plugin)
        # æ ‡è®°è¾“å‡º
        network.mark_output(swish_layer.get_output(0))

    # åºåˆ—åŒ–ç½‘ç»œ
    serialized_engine = builder.build_serialized_network(network, config)
    # åˆ›å»ºè¿è¡Œæ—¶
    runtime = trt.Runtime(logger)
    # ååºåˆ—åŒ–ç½‘ç»œ
    engine = runtime.deserialize_cuda_engine(serialized_engine)
    return engine

# æ„å»º ReLU å¼•æ“
relu_engine = build_engine(use_relu=True)
# æ„å»º Swish å¼•æ“
swish_engine = build_engine(use_relu=False)

# åˆ›å»º ReLU æ‰§è¡Œä¸Šä¸‹æ–‡
context_relu = relu_engine.create_execution_context()
# åˆ›å»º Swish æ‰§è¡Œä¸Šä¸‹æ–‡
context_swish = swish_engine.create_execution_context()

# è®¾ç½® ReLU è¾“å…¥å½¢çŠ¶
context_relu.set_input_shape("input", (1, 1024))
# è®¾ç½® Swish è¾“å…¥å½¢çŠ¶
context_swish.set_input_shape("input", (1, 1024))

# å‡†å¤‡è¾“å…¥
inp = np.random.randn(1, 1024).astype(np.float32)
# åˆ›å»º ReLU è¾“å‡º
out_relu = np.empty_like(inp)
# åˆ›å»º Swish è¾“å‡º
out_swish = np.empty_like(inp)

# åˆ†é… GPU å†…å­˜
d_input = cuda.mem_alloc(inp.nbytes)
# åˆ†é… ReLU è¾“å‡º GPU å†…å­˜
d_output_relu = cuda.mem_alloc(out_relu.nbytes)
# åˆ†é… Swish è¾“å‡º GPU å†…å­˜
d_output_swish = cuda.mem_alloc(out_swish.nbytes)

# Host â†’ Device
cuda.memcpy_htod(d_input, inp)

# æ‰§è¡Œå‡½æ•°
def run_infer(context, d_input, d_output,n_iters=50):
    # è®°å½•å¼€å§‹æ—¶é—´
    start = time.perf_counter()
    # æ‰§è¡Œæ¨ç†
    for _ in range(n_iters):
        context.execute_v2([int(d_input), int(d_output)])
    cuda.Context.synchronize()
    # è®°å½•ç»“æŸæ—¶é—´
    end = time.perf_counter()
    return (end - start) / n_iters

# æµ‹è¯• ReLU
lat_relu = run_infer(context_relu, d_input, d_output_relu)
# å¤åˆ¶ ReLU è¾“å‡ºåˆ° Host
cuda.memcpy_dtoh(out_relu, d_output_relu)

# æµ‹è¯• Swish
lat_swish = run_infer(context_swish, d_input, d_output_swish)
# å¤åˆ¶ Swish è¾“å‡ºåˆ° Host
cuda.memcpy_dtoh(out_swish, d_output_swish)

# æ‰“å°ç»“æœ
print("è¾“å…¥å®ä¾‹ï¼š", inp[0][:5])
print("ReLU è¾“å‡ºï¼š", out_relu[0][:5])
print("Swish è¾“å‡ºï¼š", out_swish[0][:5])
print(f"ReLU å¹³å‡å»¶è¿Ÿ: {lat_relu*1000:.3f} ms")
print(f"Swish å¹³å‡å»¶è¿Ÿ: {lat_swish*1000:.3f} ms")

```

------

#### 4ï¸âƒ£ è¿è¡Œæ­¥éª¤

```bash
python experiment_relu_vs_swish.py
```

------

#### 5ï¸âƒ£ ç»“æœ

è¾“å‡ºå¦‚å›¾æ‰€ç¤ºï¼ˆä¸åŒ GPU ä¼šæœ‰å·®å¼‚ï¼‰ï¼š

![image-20250906175017761](./report_day12.assets/image-20250906175017761.png)

- **æ•°å€¼æ­£ç¡®æ€§**ï¼šReLU æŠŠè´Ÿæ•°å˜æˆ 0ï¼ŒSwish å¹³æ»‘æŠ‘åˆ¶è´Ÿæ•°ã€‚
- **æ€§èƒ½ç»“æœ**ï¼šSwish æ’ä»¶æ¯”å†…ç½® ReLU ç•¥æ…¢ï¼ˆå› ä¸ºæ˜¯è‡ªå®šä¹‰ CUDA kernelï¼Œæ²¡æœ‰ cuDNN/TensorRT ä¼˜åŒ–ï¼‰ã€‚

------

### ğŸ§ª å®éªŒ 2ï¼šåŠ¨æ€ Shape æµ‹è¯•

#### 1ï¸âƒ£ å®éªŒç›®æ ‡

- éªŒè¯ `IPluginV2DynamicExt` çš„åŠŸèƒ½ï¼šè¾“å…¥ä¸åŒ batch size æ—¶ï¼Œè¾“å‡º shape æ˜¯å¦è‡ªåŠ¨åŒ¹é…ã€‚
- æµ‹è¯•è¾“å…¥ `(1,16)`ã€`(8,16)`ã€`(32,16)`ã€‚

------

#### 2ï¸âƒ£ å®éªŒæ–¹æ³•

1. æ„å»ºä¸€ä¸ªç®€å•ç½‘ç»œï¼š`Input â†’ SwishPlugin â†’ Output`ã€‚
2. ä½¿ç”¨ `context.set_binding_shape()` è®¾ç½®ä¸åŒçš„è¾“å…¥ shapeã€‚
3. æ‰§è¡Œæ¨ç†å¹¶æ‰“å°è¾“å…¥/è¾“å‡º shapeï¼ŒéªŒè¯æ˜¯å¦ä¸€è‡´ã€‚

------

#### 3ï¸âƒ£ Python å®éªŒä»£ç 

ä¿å­˜ä¸º `experiment_dynamic_shape.py`ï¼š

```
import ctypes
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

# åŠ è½½æ’ä»¶åº“
ctypes.CDLL("./libswish.so")

logger = trt.Logger(trt.Logger.INFO)

# æ„å»º Swish engine
def build_swish_engine():
    builder = trt.Builder(logger)
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    config = builder.create_builder_config()
    trt.init_libnvinfer_plugins(logger, '')

    # è¾“å…¥å®šä¹‰ä¸ºåŠ¨æ€ batch
    input_tensor = network.add_input("input", trt.DataType.FLOAT, (-1, 16))

    # æ’å…¥ Swish æ’ä»¶
    creator_list = trt.get_plugin_registry().plugin_creator_list
    swish_creator = [c for c in creator_list if c.name == "SwishPlugin"][0]
    plugin = swish_creator.create_plugin("swish_layer", trt.PluginFieldCollection([]))
    swish_layer = network.add_plugin_v2([input_tensor], plugin)

    network.mark_output(swish_layer.get_output(0))

    # æ„å»º engine
    serialized_engine = builder.build_serialized_network(network, config)
    runtime = trt.Runtime(logger)
    return runtime.deserialize_cuda_engine(serialized_engine)

# æ„å»º engine å’Œ context
engine = build_swish_engine()
context = engine.create_execution_context()

# æµ‹è¯•ä¸åŒ shape
test_shapes = [(1, 16), (8, 16), (32, 16)]

for shape in test_shapes:
    print("\n===== æµ‹è¯•è¾“å…¥ shape:", shape, "=====")
    context.set_binding_shape(0, shape)
    assert context.all_binding_shapes_specified

    # å‡†å¤‡è¾“å…¥
    inp = np.random.randn(*shape).astype(np.float32)
    out = np.empty_like(inp)

    # åˆ†é…æ˜¾å­˜
    d_input = cuda.mem_alloc(inp.nbytes)
    d_output = cuda.mem_alloc(out.nbytes)

    cuda.memcpy_htod(d_input, inp)

    # æ‰§è¡Œ
    context.execute_v2([int(d_input), int(d_output)])

    cuda.memcpy_dtoh(out, d_output)

    print("è¾“å…¥ shape:", inp.shape)
    print("è¾“å‡º shape:", out.shape)
    print("è¾“å…¥å‰5ä¸ªå€¼:", inp.flatten()[:5])
    print("è¾“å‡ºå‰5ä¸ªå€¼:", out.flatten()[:5])
```

------

#### 4ï¸âƒ£ è¿è¡Œæ­¥éª¤

```
python experiment_dynamic_shape.py
```

------

#### 5ï¸âƒ£ é¢„æœŸç»“æœ

è¾“å‡ºï¼š

![image-20250906183739624](./report_day12.assets/image-20250906183739624.png)

------

### ğŸ§ª å®éªŒ 3ï¼šåºåˆ—åŒ–/ååºåˆ—åŒ–

#### 1ï¸âƒ£ å®éªŒç›®æ ‡

- æµ‹è¯• TensorRT Engine çš„ **æŒä¹…åŒ–èƒ½åŠ›**ã€‚
- éªŒè¯ `SwishPlugin` çš„åºåˆ—åŒ–æ¥å£æ˜¯å¦æ­£ç¡®å®ç°ã€‚
- ç¡®è®¤ **ä¿å­˜å‰åæ¨ç†ç»“æœä¸€è‡´**ã€‚

------

#### 2ï¸âƒ£ å®éªŒæ–¹æ³•

1. æ„å»ºå¸¦ `SwishPlugin` çš„ Engineã€‚
2. åºåˆ—åŒ–ä¸ºäºŒè¿›åˆ¶ `.engine` æ–‡ä»¶å¹¶å†™å…¥ç£ç›˜ã€‚
3. é‡æ–°åŠ è½½ `.engine`ï¼Œåˆ›å»º ExecutionContextã€‚
4. åœ¨ç›¸åŒè¾“å…¥ä¸‹è¿è¡Œæ¨ç†ï¼Œå¯¹æ¯”è¾“å‡ºã€‚

------

#### 3ï¸âƒ£ Python å®éªŒä»£ç 

ä¿å­˜ä¸º `experiment_serialize.py`ï¼š

```python
import ctypes
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

# åŠ è½½æ’ä»¶åº“
ctypes.CDLL("./libswish.so")

# æ—¥å¿—
logger = trt.Logger(trt.Logger.INFO)

def build_engine():
    # åˆ›å»º builder
    builder = trt.Builder(logger)
    # åˆ›å»ºç½‘ç»œ
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    # åˆ›å»ºé…ç½®
    config = builder.create_builder_config()
    # åˆå§‹åŒ–æ’ä»¶
    trt.init_libnvinfer_plugins(logger,'')

    # åˆ›å»ºè¾“å…¥
    input_tensor = network.add_input("input",trt.DataType.FLOAT,(1,16))

    # è·å–æ’ä»¶åˆ—è¡¨
    creator_list = trt.get_plugin_registry().plugin_creator_list
    # è·å– Swish æ’ä»¶
    swish_creator = [c for c in creator_list if c.name == "SwishPlugin"][0]
    # åˆ›å»º Swish æ’ä»¶
    plugin = swish_creator.create_plugin("swish_layer",trt.PluginFieldCollection([]))
    # åˆ›å»º Swish å±‚
    swish_layer = network.add_plugin_v2([input_tensor],plugin)
    # æ ‡è®°è¾“å‡º
    network.mark_output(swish_layer.get_output(0))

    # åºåˆ—åŒ–ç½‘ç»œ
    serialized_engine = builder.build_serialized_network(network,config)
    # åˆ›å»ºè¿è¡Œæ—¶
    runtime = trt.Runtime(logger)
    # ååºåˆ—åŒ–ç½‘ç»œ
    engine = runtime.deserialize_cuda_engine(serialized_engine)
    # è¿”å›å¼•æ“å’Œåºåˆ—åŒ–åçš„ç½‘ç»œ
    return engine,serialized_engine

# æ„å»ºå¼•æ“
engine,serialized_engine = build_engine()

# ä¿å­˜å¼•æ“
with open("swish.engine","wb") as f:
    f.write(serialized_engine)
print("âœ… Engine å·²ä¿å­˜åˆ° swish.engine")

# åŠ è½½å¼•æ“
with open("swish.engine","rb") as f:
    engine_data = f.read()

# åˆ›å»ºè¿è¡Œæ—¶
runtime = trt.Runtime(logger)
# ååºåˆ—åŒ–ç½‘ç»œ
engine_loaded = runtime.deserialize_cuda_engine(engine_data)
print("âœ… Engine å·²ä» swish.engine åŠ è½½æˆåŠŸ")

# è¿è¡Œæ¨ç†
def run_infer(engine,inp):
    # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
    context = engine.create_execution_context()
    # è®¾ç½®è¾“å…¥å½¢çŠ¶
    context.set_binding_shape(0,inp.shape)
    # åˆ›å»ºè¾“å‡º
    out = np.empty_like(inp)
    # åˆ›å»ºè¾“å…¥ GPU å†…å­˜
    d_input = cuda.mem_alloc(inp.nbytes)
    # åˆ›å»ºè¾“å‡º GPU å†…å­˜
    d_output = cuda.mem_alloc(out.nbytes)

    # Host â†’ Device
    cuda.memcpy_htod(d_input,inp)
    # æ‰§è¡Œæ¨ç†
    context.execute_v2([int(d_input),int(d_output)])
    # Device â†’ Host
    cuda.memcpy_dtoh(out,d_output)
    return out

# åˆ›å»ºè¾“å…¥
inp = np.random.randn(1,16).astype(np.float32)

# è¿è¡Œæ¨ç†
out_before = run_infer(engine,inp)
out_after = run_infer(engine_loaded,inp)

print("è¾“å…¥:", inp[0, :5])
print("ä¿å­˜å‰è¾“å‡º:", out_before[0, :5])
print("ä¿å­˜åè¾“å‡º:", out_after[0, :5])

# è®¡ç®—æœ€å¤§å·®å¼‚
diff = np.max(np.abs(out_before - out_after))
print("æœ€å¤§å·®å¼‚:", diff)

```

------

#### 4ï¸âƒ£ è¿è¡Œæ­¥éª¤

```bash
python experiment_serialize.py
```

------

#### 5ï¸âƒ£ ç»“æœ

è¾“å‡ºï¼š

![image-20250906200856540](./report_day12.assets/image-20250906200856540.png)

- âœ… è¾“å‡º shape æ­£ç¡®
- âœ… ä¿å­˜å‰åè¾“å‡ºå®Œå…¨ä¸€è‡´
- âœ… è¯´æ˜ `SwishPlugin` çš„åºåˆ—åŒ–/ååºåˆ—åŒ–é€»è¾‘æ­£ç¡®

------

### ğŸ§ª å®éªŒ 4ï¼šå¤šçº¿ç¨‹å¹¶å‘

#### 1ï¸âƒ£ å®éªŒç›®æ ‡

- æ£€æŸ¥ `SwishPlugin` åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹æ˜¯å¦å®‰å…¨ã€‚
- å¤šä¸ªçº¿ç¨‹åŒæ—¶è¿è¡Œæ¨ç†ï¼ŒéªŒè¯æ—  crashã€‚
- å¯¹æ¯”ä¸åŒçº¿ç¨‹æ•°ä¸‹çš„æ¨ç†æ€§èƒ½ï¼Œè§‚å¯Ÿæ˜¯å¦æ¥è¿‘çº¿æ€§æå‡ã€‚

------

#### 2ï¸âƒ£ å®éªŒæ–¹æ³•

1. æ„å»ºåŒä¸€ä¸ª `SwishPlugin` engineã€‚
2. ç”¨ `threading.Thread` å¯åŠ¨å¤šä¸ªæ¨ç†çº¿ç¨‹ã€‚
3. æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œå¤šæ¬¡æ¨ç†å¹¶è®¡æ—¶ã€‚
4. æ¯”è¾ƒ **å•çº¿ç¨‹ vs å¤šçº¿ç¨‹** çš„å¹³å‡è€—æ—¶ã€‚

------

#### 3ï¸âƒ£ Python å®éªŒä»£ç 

ä¿å­˜ä¸º `experiment_multithread.py`ï¼š

```python
import ctypes
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.tools as cuda_tools
import pycuda.autoinit
import threading,time

# åŠ è½½æ’ä»¶
ctypes.CDLL("./libswish.so")

# åˆ›å»ºæ—¥å¿—å™¨
logger = trt.Logger(trt.Logger.INFO)

def build_engine():
    # åˆ›å»ºæ„å»ºå™¨
    builder = trt.Builder(logger)
    # åˆ›å»ºç½‘ç»œ
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    # åˆ›å»ºé…ç½®
    config = builder.create_builder_config()
    # åˆå§‹åŒ–æ’ä»¶
    trt.init_libnvinfer_plugins(logger,'')

    # åˆ›å»ºè¾“å…¥
    input_tensor = network.add_input("input",trt.DataType.FLOAT,(1,16))
    # è·å–æ’ä»¶åˆ—è¡¨
    creator_list = trt.get_plugin_registry().plugin_creator_list
    # è·å– Swish æ’ä»¶
    swish_creator = [c for c in creator_list if c.name == "SwishPlugin"][0]
    # åˆ›å»º Swish æ’ä»¶
    plugin = swish_creator.create_plugin("swish_layer",trt.PluginFieldCollection([]))
    # åˆ›å»º Swish å±‚
    swish_layer = network.add_plugin_v2([input_tensor],plugin)
    # æ ‡è®°è¾“å‡º
    network.mark_output(swish_layer.get_output(0))

    # åºåˆ—åŒ–ç½‘ç»œ
    serialized_engine = builder.build_serialized_network(network,config)
    # åˆ›å»ºè¿è¡Œæ—¶
    runtime = trt.Runtime(logger)
    # ååºåˆ—åŒ–ç½‘ç»œ
    return runtime.deserialize_cuda_engine(serialized_engine)

# åˆ›å»ºå¼•æ“
engine = build_engine()

def run_infer(thread_id,n_iters=50):
    # åˆ›å»º CUDA ä¸Šä¸‹æ–‡
    ctx = cuda.Device(0).make_context()
    try:
        # åˆ›å»º TensorRT æ‰§è¡Œä¸Šä¸‹æ–‡
        trt_context = engine.create_execution_context()
        # åˆ›å»ºè¾“å…¥
        inp = np.random.randn(1,16).astype(np.float32)
        # åˆ›å»ºè¾“å‡º
        out = np.empty_like(inp)

        # åˆ›å»ºè¾“å…¥ GPU å†…å­˜
        d_input = cuda.mem_alloc(inp.nbytes)
        # åˆ›å»ºè¾“å‡º GPU å†…å­˜
        d_output = cuda.mem_alloc(out.nbytes)

        # è®°å½•å¼€å§‹æ—¶é—´
        start = time.perf_counter()

        for _ in range(n_iters):
            # Host â†’ Device
            cuda.memcpy_htod(d_input,inp)
            # æ‰§è¡Œæ¨ç†
            trt_context.execute_v2([int(d_input),int(d_output)])
            # Device â†’ Host
            cuda.memcpy_dtoh(out,d_output)
        # åŒæ­¥ CUDA ä¸Šä¸‹æ–‡
        cuda.Context.synchronize()
        # è®°å½•ç»“æŸæ—¶é—´
        end = time.perf_counter()

        # è®¡ç®—å¹³å‡è€—æ—¶
        avg_time = (end - start) / n_iters * 1000
        print(f"[çº¿ç¨‹ {thread_id}] å¹³å‡è€—æ—¶: {avg_time:.3f} ms")
    finally:
        # å¼¹å‡º CUDA ä¸Šä¸‹æ–‡
        ctx.pop()

def test_multithread(n_threads=4):
    # åˆ›å»ºçº¿ç¨‹åˆ—è¡¨
    threads = []
    # è®°å½•å¼€å§‹æ—¶é—´
    start = time.perf_counter()
    # åˆ›å»ºçº¿ç¨‹
    for i in range(n_threads):
        t = threading.Thread(target=run_infer,args=(i,))
        # å¯åŠ¨çº¿ç¨‹
        t.start()
        # æ·»åŠ çº¿ç¨‹åˆ°åˆ—è¡¨
        threads.append(t)
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for t in threads:
        # ç­‰å¾…çº¿ç¨‹å®Œæˆ
        t.join()
    # è®°å½•ç»“æŸæ—¶é—´
    end = time.perf_counter()
    print(f"ğŸ”¥ {n_threads} çº¿ç¨‹æ€»è€—æ—¶: {(end - start)*1000:.2f} ms")

if __name__ == "__main__":
    # å•çº¿ç¨‹æµ‹è¯•
    print("=====å•çº¿ç¨‹====")
    test_multithread(1)

    # åŒçº¿ç¨‹æµ‹è¯•
    print("\n====åŒçº¿ç¨‹====")
    test_multithread(2)

    # å››çº¿ç¨‹æµ‹è¯•
    print("\n====å››çº¿ç¨‹====")
    test_multithread(4)

```

------

#### 4ï¸âƒ£ è¿è¡Œæ–¹å¼

```bash
python experiment_multithread.py
```

------

#### 5ï¸âƒ£ é¢„æœŸç»“æœ

è¾“å‡ºï¼ˆä¸åŒ GPU ä¼šæœ‰å·®å¼‚ï¼‰ï¼š

![image-20250906231814316](./report_day12.assets/image-20250906231814316.png)

------

#### ğŸ¯ ç»“è®º

- **åŠŸèƒ½æ­£ç¡®æ€§**ï¼šSwishPlugin åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹è¿è¡Œç¨³å®šï¼Œæ—  crashã€‚
- **æ€§èƒ½è¡¨ç°**ï¼šå•ä¸ªçº¿ç¨‹å†…çš„å»¶è¿ŸåŸºæœ¬ç¨³å®šã€‚
- **ååæå‡**ï¼šå¤šçº¿ç¨‹èƒ½æé«˜æ•´ä½“ååï¼Œä½†ç”±äº GPU æ˜¯å…±äº«èµ„æºï¼Œé€Ÿåº¦ä¸ä¼šä¸¥æ ¼çº¿æ€§æå‡ï¼ˆå—é™äº SM èµ„æºå’Œä¸Šä¸‹æ–‡åˆ‡æ¢ï¼‰ã€‚

------

### ğŸ§ª å®éªŒ 5ï¼šæ€§èƒ½ Profiling

####  1ï¸âƒ£ å®éªŒç›®æ ‡

- ä½¿ç”¨ **Nsight Systems (`nsys`)** æŸ¥çœ‹ **æ•´ä½“æ—¶é—´çº¿**
- ä½¿ç”¨ **Nsight Compute (`ncu`)** æŸ¥çœ‹ **å•ä¸ª kernel è¯¦æƒ…**
- é‡ç‚¹å…³æ³¨ï¼š
  - kernel è°ƒåº¦æ˜¯å¦è¿ç»­ï¼ˆæœ‰æ²¡æœ‰ç©ºæ´ï¼‰
  - æ˜¯å¦å­˜åœ¨é¢å¤– **cudaMemcpy**
  - æ˜¯å¦å’Œå…¶ä»–ç®—å­ overlap

------

#### 2ï¸âƒ£  å‡†å¤‡ä¸€ä¸ªç‹¬ç«‹çš„å¯æ‰§è¡Œç¨‹åº

ä¹‹å‰æˆ‘ä»¬ç”¨çš„æ˜¯ Python æµ‹è¯•ï¼Œç°åœ¨æˆ‘ä»¬è¦å†™ä¸€ä¸ª **C++ ç¨‹åº `plugin_test.cpp`**ï¼Œå®ƒä¼šï¼š

1. åŠ è½½ `libswish.so`
2. æ„å»ºä¸€ä¸ªæœ€ç®€å•çš„ TensorRT engineï¼ˆè¾“å…¥ â†’ Swish â†’ è¾“å‡ºï¼‰
3. è¿è¡Œå‡ æ¬¡æ¨ç†

è¿™æ · `nsys` å’Œ `ncu` æ‰èƒ½ profile å‡º kernelã€‚

```c++
#include <NvInfer.h>
#include <cassert>
#include <cuda_runtime.h>
#include <dlfcn.h>
#include <iostream>
#include <vector>

using namespace nvinfer1;

// æ—¥å¿—å™¨
class Logger : public ILogger
{
    // è®°å½•æ—¥å¿—
    void log(Severity severity, const char* msg) noexcept override
    {
        // åªè®°å½• INFO çº§åˆ«çš„æ—¥å¿—
        if (severity <= Severity::kINFO)
        {
            std::cout << msg << std::endl;
        }
    }
};

int main()
{
    // åŠ è½½æ’ä»¶åº“
    void* handle = dlopen("./libswish.so", RTLD_LAZY);
    if (!handle)
    {
        std::cerr << "âŒ Failed to load libswish.so: " << dlerror() << std::endl;
        return -1;
    }

    // åˆ›å»ºæ—¥å¿—å™¨
    Logger logger;
    // åˆ›å»ºæ„å»ºå™¨
    IBuilder* builder = createInferBuilder(logger);
    // åˆ›å»ºé…ç½®
    IBuilderConfig* config = builder->createBuilderConfig();
    // åˆ›å»ºç½‘ç»œ
    auto network = builder->createNetworkV2(
        1U << static_cast<int>(NetworkDefinitionCreationFlag::kEXPLICIT_BATCH));
    // åˆ›å»ºè¾“å…¥
    ITensor* input = network->addInput("input", DataType::kFLOAT, Dims2{1, 16});
    // è·å–æ’ä»¶æ³¨å†Œè¡¨
    auto* registy = getPluginRegistry();
    // è·å–æ’ä»¶åˆ›å»ºè€…æ•°é‡
    int32_t numCreators = 0;
    auto creatorList = registy->getPluginCreatorList(&numCreators);
    // è·å– Swish æ’ä»¶åˆ›å»ºè€…
    IPluginCreator* swish_creator = nullptr;
    for (int i = 0; i < numCreators; i++)
    {
        // è·å–æ’ä»¶åç§°
        if (std::string(creatorList[i]->getPluginName()) == "SwishPlugin")
        {
            // è·å– Swish æ’ä»¶åˆ›å»ºè€…
            swish_creator = creatorList[i];
            break;
        }
    }
    // æ–­è¨€ Swish æ’ä»¶åˆ›å»ºè€…ä¸ä¸ºç©º
    assert(swish_creator && "SwishPlugin not found!");

    // åˆ›å»ºæ’ä»¶å­—æ®µé›†åˆ
    PluginFieldCollection fc{};
    // åˆ›å»º Swish æ’ä»¶
    IPluginV2* plugin = swish_creator->createPlugin("swish_layer", &fc);
    // åˆ›å»º Swish å±‚
    auto swish_layer = network->addPluginV2(&input, 1, *plugin);
    // æ ‡è®°è¾“å‡º
    network->markOutput(*swish_layer->getOutput(0));

    // åºåˆ—åŒ–ç½‘ç»œ
    IHostMemory* serialized = builder->buildSerializedNetwork(*network, *config);
    // åˆ›å»ºè¿è¡Œæ—¶
    IRuntime* runtime = createInferRuntime(logger);
    // ååºåˆ—åŒ–ç½‘ç»œ
    ICudaEngine* engine = runtime->deserializeCudaEngine(serialized->data(), serialized->size());
    // åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
    IExecutionContext* context = engine->createExecutionContext();

    // åˆ›å»ºè¾“å…¥å’Œè¾“å‡º
    std::vector<float> h_input(16, 1.0f), h_output(16, 0.0f);
    float *d_input, *d_output;
    // åˆ†é…è¾“å…¥ GPU å†…å­˜
    cudaMalloc(&d_input, h_input.size() * sizeof(float));
    // åˆ†é…è¾“å‡º GPU å†…å­˜
    cudaMalloc(&d_output, h_output.size() * sizeof(float));

    for (int i = 0; i < 100; i++)
    {
        // Host â†’ Device
        cudaMemcpy(d_input, h_input.data(), h_input.size() * sizeof(float), cudaMemcpyHostToDevice);
        // åˆ›å»ºç»‘å®š
        void* bindings[] = {d_input, d_output};
        // æ‰§è¡Œæ¨ç†
        context->executeV2(bindings);
        // Device â†’ Host
        cudaMemcpy(h_output.data(), d_output, h_output.size() * sizeof(float),
                   cudaMemcpyDeviceToHost);
    }
    std::cout << "âœ… Done, first output: " << h_output[0] << std::endl;
    // é‡Šæ”¾è¾“å…¥ GPU å†…å­˜
    cudaFree(d_input);
    cudaFree(d_output);
    // é‡Šæ”¾æ‰§è¡Œä¸Šä¸‹æ–‡
    delete context;
    // é‡Šæ”¾å¼•æ“
    delete engine;
    // é‡Šæ”¾è¿è¡Œæ—¶
    delete runtime;
    // é‡Šæ”¾åºåˆ—åŒ–ç½‘ç»œ
    delete serialized;
    delete network;
    // é‡Šæ”¾é…ç½®
    delete config;
    // é‡Šæ”¾æ„å»ºå™¨
    delete builder;

    return 0;
}

```

------

#### 3ï¸âƒ£ ç¼–è¯‘

```bash
g++ plugin_test.cpp -o plugin_test \
  -I/usr/include/x86_64-linux-gnu \
  -I/usr/local/cuda/include \
  -L/usr/lib/x86_64-linux-gnu \
  -L/usr/local/cuda/lib64 \
  -lnvinfer -lnvonnxparser -lcudart -ldl
```

> æ³¨æ„ï¼šæŠŠ `/path/to/TensorRT/` æ¢æˆä½ å®¹å™¨é‡Œçš„å®é™…è·¯å¾„ï¼Œæ¯”å¦‚ `/usr/lib/x86_64-linux-gnu/`.

------

#### 4ï¸âƒ£ ç”¨ Nsight Systems è·‘

```bash
nsys profile -o profile_report ./plugin_test
```

ç”Ÿæˆæ–‡ä»¶ï¼š`profile_report.qdrep`

ç„¶åä½ å¯ä»¥ä¸‹è½½åˆ°æœ¬åœ°ç”¨ **Nsight Systems GUI** æ‰“å¼€ï¼ŒæŸ¥çœ‹ï¼š

- Timeline ä¸Šçš„ **kernel è°ƒåº¦**
- æ˜¯å¦æœ‰ **cudaMemcpy**
- æ˜¯å¦æœ‰ç©ºéš™ï¼ˆGPU idleï¼‰

------

#### 5ï¸âƒ£ ç”¨ Nsight Compute è·‘

```bash
ncu --set full --target-processes all ./plugin_test
```

è¿™ä¼šè¾“å‡ºï¼š

- æ¯ä¸ª kernel çš„è€—æ—¶
- Occupancyã€warp divergence
- Memory throughput

------

#### 6ï¸âƒ£ åˆ†ææŒ‡æ ‡

é‡ç‚¹å…³æ³¨ï¼š

- **Warp Divergence** < 5%ï¼ˆæ¿€æ´»å‡½æ•°ç®—å­åº”è¯¥å¾ˆä½ï¼‰
- **Memory Throughput** æ¥è¿‘ç†è®ºå¸¦å®½
- **Shared Memory Utilization**ï¼ˆå¦‚æœ Swish ç”¨åˆ°äº†ï¼‰
- æ˜¯å¦æœ‰ **é¢å¤– memcpy**ï¼ˆæ’ä»¶å†…éƒ¨ä¸åº”å†æœ‰ï¼‰

------

## âœ… æ€»ç»“

1. Plugin æ˜¯æ‰©å±• TensorRT çš„å…³é”®æœºåˆ¶ï¼Œç”¨äºæ”¯æŒ **æœªå†…ç½®ç®—å­** æˆ– **ç‰¹æ®Šä¼˜åŒ–**ã€‚
2. æœ¬æ–‡å®ç°äº†ä¸€ä¸ª **Swish Plugin**ï¼Œå®Œæ•´è¦†ç›–äº†æ¥å£ã€åºåˆ—åŒ–ã€åŠ¨æ€ shapeã€æ¨ç†ã€‚
3. é€šè¿‡å®éªŒéªŒè¯äº† Plugin çš„åŠŸèƒ½ã€æ€§èƒ½ä¸å…¼å®¹æ€§ã€‚
4. Nsight åˆ†æèƒ½å¸®åŠ©å®šä½ Plugin çš„å†…å­˜/ç®—åŠ›ç“¶é¢ˆã€‚
5. æœ€ä½³å®è·µï¼š**é¿å…å…¨å±€å˜é‡ã€ä¿è¯åºåˆ—åŒ–å…¼å®¹ã€æµ‹è¯•åŠ¨æ€ shapeã€å®‰å…¨å¹¶å‘**ã€‚
6. ä¸‹ä¸€æ­¥å¯ä»¥å°è¯• **æ›´å¤æ‚ Pluginï¼ˆå¦‚ LayerNormã€Attentionï¼‰**ï¼Œå¹¶ä¸å†…ç½®ç®—å­æ€§èƒ½å¯¹æ¯”ã€‚