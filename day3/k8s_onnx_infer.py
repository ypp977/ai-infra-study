import onnxruntime as ort
import numpy as np

# æ¨¡å‹è·¯å¾„ï¼ˆé€šè¿‡ ConfigMap æŒ‚è½½åˆ° /workspace/modelsï¼‰
MODEL_PATH = "/workspace/models/mlp.onnx"

print(f"ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
sess = ort.InferenceSession(MODEL_PATH, providers=["CPUExecutionProvider"])

# éšæœºè¾“å…¥æµ‹è¯•
x = np.random.randn(1, 1, 28, 28).astype(np.float32)
inputs = {sess.get_inputs()[0].name: x}
outputs = sess.run(None, inputs)

print("âœ… æ¨ç†ç»“æœ:", outputs[0])

