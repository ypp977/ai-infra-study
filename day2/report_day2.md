# Day 2 â€”Kubernetes åŸºç¡€ & GPU Pod

## ä¸€ã€ğŸ¯å­¦ä¹ ç›®æ ‡

- å­¦ä¼šåŸºæœ¬çš„ `kubectl` å‘½ä»¤
- ä½¿ç”¨ **minikube + docker driver** å¯åŠ¨ K8s
- éƒ¨ç½² **NVIDIA GPU Podï¼ˆå¸¦ nvidia-device-pluginï¼‰**
- åœ¨é›†ç¾¤é‡Œè¿è¡Œ PyTorch å®¹å™¨å¹¶éªŒè¯ GPU

## äºŒã€å®‰è£…å¹¶å¯åŠ¨ Minikube

> âš ï¸ æ³¨æ„ï¼šå¿…é¡»ç”¨ **vipuser** ç”¨æˆ·ï¼ˆé rootï¼‰ï¼Œå¦åˆ™ä¼šæŠ¥ `DRV_AS_ROOT` é”™è¯¯ã€‚

### 1) å®‰è£…minikube

```bash
curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
rm -f minikube-linux-amd64
minikube version
```

![image-20250824205401477](./report_day2.assets/image-20250824205401477.png)

### 2) ç¡®è®¤ **kubectl** å¯ç”¨

```bash
# å¦‚æœä½ æœºå™¨ä¸Šè¿˜æ²¡æœ‰ kubectlï¼š
sudo snap install kubectl --classic  # æˆ–è€…ç”¨ä½ ä¹‹å‰è£…å¥½çš„ç‰ˆæœ¬
# ç¡®ä¿ PATH é‡ŒåŒ…å« /snap/binï¼ˆå½“å‰ shell ç«‹å³ç”Ÿæ•ˆï¼‰
export PATH=/snap/bin:$PATH
kubectl version --client
```

![image-20250824205655580](./report_day2.assets/image-20250824205655580.png)

### 3) å¯åŠ¨é›†ç¾¤ï¼ˆDocker é©±åŠ¨ + é˜¿é‡Œé•œåƒä»“åº“ + æŒ‡å®šç‰ˆæœ¬ï¼‰

> å¿…é¡»ç”¨ **vipuser**ï¼ˆé rootï¼‰è¿è¡Œã€‚ä½ çš„æœºå™¨å·²é…ç½® nvidia-container-toolkitã€‚é•œåƒä¸‹è½½å¤±è´¥è¯·æŒ‚ä»£ç†ï¼Œæˆ–è€…æå‰ä¸‹è½½é•œåƒä½œä¸ºcache

```bash
# 0) æ¸…ç†æ—§ç¯å¢ƒï¼ˆå¯é€‰ï¼‰
minikube delete --all --purge || true
rm -f ~/.minikube/cache/images/kicbase-v0.0.47-amd64* || true

KIC_VER=v0.0.47
K8S_VER=v1.30.4   # å¦‚æœè¿˜ä¸è¡Œï¼Œå¯é™åˆ° v1.29.x
minikube start \
  --driver=docker \
  --kubernetes-version=${K8S_VER} \
  --image-repository=auto \
  --base-image=gcr.io/k8s-minikube/kicbase:${KIC_VER} \
  --gpus=all \
  --force-systemd=true \
  -v=3

```

æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€åº”ä¸º `Ready`ã€‚ï¼š

```bash
kubectl get nodes -o wide
```

![image-20250824212916612](./report_day2.assets/image-20250824212916612.png)

## 4) å®‰è£… **NVIDIA Device Plugin**

```bash
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.17.3/deployments/static/nvidia-device-plugin.yml
kubectl -n kube-system get pods -l name=nvidia-device-plugin-ds -w
```

![image-20250826012055919](./report_day2.assets/image-20250826012055919.png)

## 5) è·‘ä¸€ä¸ª GPU Pod éªŒè¯

ä¿å­˜ä¸º `gpu-test.yaml`ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-version
spec:
  restartPolicy: Never
  containers:
  - name: test
    image: nvcr.io/nvidia/pytorch:25.06-py3
    resources:
      limits:
        nvidia.com/gpu: 1
    command: ["bash","-lc"]
    args:
      - |
        python - <<'PY'
        import torch
        print("CUDA:", torch.cuda.is_available())
        if torch.cuda.is_available():
            print("GPU:", torch.cuda.get_device_name(0))
        PY

```

åº”ç”¨å¹¶çœ‹æ—¥å¿—ï¼š

```bash
kubectl apply -f gpu-version.yaml  # kubectl describe pod gpu-version æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—
kubectl get pod gpu-version -w
kubectl logs gpu-version

kubectl delete pod gpu-version # åˆ é™¤pod
```

![image-20250826035958949](./report_day2.assets/image-20250826035958949.png)![image-20250826040024659](./report_day2.assets/image-20250826040024659.png)

çœ‹åˆ°ï¼š

![image-20250826035903226](./report_day2.assets/image-20250826035903226.png)
