# Day 1-Docker & GPU å®¹å™¨åŒ–


## ä¸€ã€ ğŸ¯ å­¦ä¹ ç›®æ ‡

- åœ¨ **vipuser** è´¦å·ä¸‹å®‰è£…å¹¶é…ç½® Dockerï¼ˆå« NVIDIA å®¹å™¨è¿è¡Œæ—¶ï¼‰
- ä½¿ç”¨ **docker.xuanyuan.me** ä½œä¸ºé•œåƒåŠ é€Ÿ
- åŸºäº **NGC å®˜æ–¹ PyTorch é•œåƒ**ï¼ˆå« TensorRT SDKï¼‰æ„å»ºæœ€å°æ¨ç†ç¯å¢ƒ
- åœ¨å®¹å™¨é‡ŒåŒæ—¶éªŒè¯ **PyTorch + ONNX Runtime + TensorRT** å¯ç”¨

## äºŒã€ç”¨ **vipuser** ç™»å½•

```bash
# å›åˆ°æ™®é€šç”¨æˆ·ï¼ˆé rootï¼‰
whoami        # åº”æ˜¾ç¤º vipuser
```

> ä¹‹åæ‰€æœ‰å‘½ä»¤éƒ½ä»¥ `vipuser` æ‰§è¡Œï¼ˆé‡åˆ°ç³»ç»Ÿçº§æ“ä½œç”¨ sudoï¼‰ã€‚

![image-20250824190534668](./report_day1.assets/image-20250824190534668.png)

### 1) åŸºç¡€å·¥å…· & DNS/è¯ä¹¦å…œåº•ï¼ˆé¿å…ç½‘ç»œ/è¯ä¹¦å¯¼è‡´çš„ curl/apt å¤±è´¥ï¼‰

```bash
sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg lsb-release
sudo update-ca-certificates
```

### 2) å®‰è£… Docker CEï¼ˆå®˜æ–¹ä¸€é”®è„šæœ¬ï¼Œé‡ç½‘ç»œé—®é¢˜è‡ªåŠ¨é‡è¯•ï¼‰

```bash
curl -fsSL https://get.docker.com | sudo sh || \
{ echo "Docker å®‰è£…å¤±è´¥ï¼Œå°è¯• apt æºå®‰è£…"; \
  sudo apt-get update && \
  sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin; }
```

æŠŠ **vipuser åŠ å…¥ docker ç»„**ï¼ˆé€€å‡ºå¹¶é‡æ–°ç™»å½•ä¸€æ¬¡è®©ç»„æƒé™ç”Ÿæ•ˆï¼‰ï¼š

```bash
sudo usermod -aG docker $USER
newgrp docker  # è®©å½“å‰ shell ç«‹å³ç”Ÿæ•ˆï¼Œæˆ–é‡æ–°ç™»å½•
docker ps      # ä¸ç”¨ sudo å°±èƒ½è·‘æˆåŠŸ
```

è¿è¡Œç»“æœå¦‚å›¾æ‰€ç¤ºï¼ŒåŒ…å«dockerç‰ˆæœ¬å’Œdocker pså‘½ä»¤è¿è¡Œç»“æœï¼š

![image-20250824192602891](./report_day1.assets/image-20250824192602891.png)

### 3) å®‰è£… NVIDIA Container Toolkitï¼ˆnvidia-dockerï¼‰

```bash
# æ·»åŠ å®˜æ–¹ Keyring ä¸æº
distribution=$(. /etc/os-release; echo $ID$VERSION_ID) && \
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
  sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -fsSL https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
```

é…ç½® Docker ä½¿ç”¨ NVIDIA runtimeï¼š

```bash
sudo nvidia-ctk runtime configure --runtime=docker
```

è¿è¡Œç»“æœå¦‚å›¾æ‰€ç¤ºï¼š![image-20250824192803430](./report_day1.assets/image-20250824192803430.png)

### 4) **å¯ç”¨â€œè½©è¾•é•œåƒâ€**å¹¶è®¾ç½®é»˜è®¤ runtime

ç¼–è¾‘ `/etc/docker/daemon.json`ï¼ˆä¸å­˜åœ¨å°±æ–°å»ºï¼‰ï¼š

```bash
cat <<'JSON' | sudo tee /etc/docker/daemon.json
{
  "registry-mirrors": ["https://docker.xuanyuan.me"],
  "exec-opts": ["native.cgroupdriver=systemd"],
  "default-runtime": "nvidia",
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  }
}
JSON

# é‡è½½å¹¶é‡å¯
sudo systemctl daemon-reload
sudo systemctl restart docker
# æ‰“å°æœ€æ–°çš„é…ç½®æ–‡ä»¶
cat  /etc/docker/daemon.json
```

ç»“æœå¦‚å›¾æ‰€ç¤ºï¼š![image-20250824192914438](./report_day1.assets/image-20250824192914438.png)

### 5) GPU å®¹å™¨åŸºç¡€è‡ªæ£€ï¼ˆæ’é™¤é©±åŠ¨/è¿è¡Œæ—¶é—®é¢˜ï¼‰

```
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
```

çœ‹åˆ°ä¸¤å¼  **RTX 3090** ä¸é©±åŠ¨/CUDA ç‰ˆæœ¬ï¼Œè¯´æ˜å®¹å™¨å†… GPU é€šäº†

![image-20250824193105273](./report_day1.assets/image-20250824193105273.png)

### 6) æ„å»º AI ç¯å¢ƒé•œåƒï¼ˆåŒ…å«PyTorch + ONNX + TensorRT SDKï¼‰

åœ¨ `day1/` ç›®å½•ä¸‹åˆ›å»º `Dockerfile`ï¼š

```dockerfile
# NGC å®˜æ–¹ PyTorch é•œåƒï¼ˆå« CUDA/cuDNN/NCCL + TRT SDKï¼‰
FROM nvcr.io/nvidia/pytorch:25.06-py3

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_NO_CACHE_DIR=1 PIP_DEFAULT_TIMEOUT=120 PIP_RETRIES=5

# åªè¡¥å¿…è¦å·¥å…·
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates curl && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace

# ä»…è¡¥ ONNX + ORTï¼ˆTRT SDK å·²åœ¨åŸºé•œåƒé‡Œï¼‰
RUN python -m pip install --extra-index-url https://pypi.org/simple -i https://mirrors.aliyun.com/pypi/simple \
    --only-binary=:all: --prefer-binary \
    onnx==1.16.1 onnxruntime-gpu==1.20.0

# å¿«é€Ÿè‡ªæ£€ï¼Œæ„å»ºæ—¶å°±èƒ½æ—©å‘ç°ç¯å¢ƒé—®é¢˜ï¼ˆå¯æ³¨é‡Šï¼‰
RUN python - <<'PY'
import sys, torch, onnx, onnxruntime as ort
print("Python:", sys.version.split()[0])
print("Torch:", torch.__version__, "| CUDA:", torch.version.cuda, "| cuDNN:", torch.backends.cudnn.version())
print("ONNX:", onnx.__version__)
print("ORT:", ort.__version__, "| Providers:", ort.get_available_providers())
PY
```

**åˆ›å»ºæ–‡ä»¶torch_check.pyï¼ˆå®¹å™¨å†…è¿è¡Œï¼‰**

```python
import torch, onnxruntime as ort, platform
print("Torch:", torch.__version__, "| Python:", platform.python_version())
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU count:", torch.cuda.device_count())
    for i in range(torch.cuda.device_count()):
        print(f"  [{i}] {torch.cuda.get_device_name(i)}")
print("ORT:", ort.__version__)
print("Providers:", ort.get_available_providers())
```

**æ„å»º & è¿è¡Œï¼š**

```bash
cd ~/ai-infra-study/day1
docker build -t ai-infra:day1 .
docker run --gpus all --rm -it -v $PWD:/workspace ai-infra:day1 bash -lc "python torch_check.py"
```


