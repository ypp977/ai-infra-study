# Day11 - CUDA å®æˆ˜é¡¹ç›®

------

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- å®Œæˆ **CPU vs GPU çŸ©é˜µä¹˜æ³•æ€§èƒ½å¯¹æ¯”**
- åœ¨ GPU ä¸Šå®ç° **Shared Memory Tiling ä¼˜åŒ–**
- è°ƒæ•´ **tile/block å°ºå¯¸**ï¼Œåˆ†æå¯„å­˜å™¨/å…±äº«å†…å­˜å ç”¨ä¸æ€§èƒ½å…³ç³»
- ç”¨ Nsight Compute åˆ†æç“¶é¢ˆï¼Œç†è§£ **ç®—å¼º/è®¿å­˜æ¯”** å’Œ **occupancy**
- æ¢ç´¢ **åŒç¼“å†² (double buffering)** ä¸ **FP16 è¾“å…¥ã€FP32 ç´¯åŠ **çš„æ€§èƒ½/ç²¾åº¦æƒè¡¡

------

## 1ï¸âƒ£ ä»£ç å®éªŒï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰

### 1. CPU baseline

```c++
#include <bits/stdc++.h>

using namespace std;
using namespace chrono;

void mmul_cpu(const vector<float>& A, const vector<float>& B, vector<float>& C, int N)
{
    for (int i = 0; i < N; i++)
    {
        for (int j = 0; j < N; j++)
        {
            float sum = 0.0f;
            for (int k = 0; k < N; k++)
            {
                sum += A[i * N + k] * B[k * N + j];
            }
            C[i * N + j] = sum;
        }
    }
}

int main()
{
    int N = 1024;
    vector<float> A(N * N, 1.0f), B(N * N, 1.0f), C(N * N, 0.0f);

    auto start = high_resolution_clock::now();
    mmul_cpu(A, B, C, N);

    auto end = high_resolution_clock::now();

    cout << "CPU done, C[0]=" << C[0]
         << ", time =" << duration_cast<milliseconds>(end - start).count() << " ms\n";

    return 0;
}

```

ç¼–è¯‘ & è¿è¡Œï¼š

```bash
g++ -O2 mmul_cpu.cpp -o mmul_cpu 
./mmul_cpu
```

é¢„æœŸè¾“å‡ºï¼š

![image-20250904193810501](./report_day11.assets/image-20250904193810501.png)

------

### 2. GPU naive kernel

```c++
#include <stdio.h>

__global__ void mmul_native(const float* A, const float* B, float* C, int N)
{
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < N && col < N)
    {
        float sum = 0.0f;
        for (int k = 0; k < N; k++)
        {
            sum += A[row * N + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}

int main()
{
    int N = 1024;
    size_t size = N * N * sizeof(float);

    float *host_a, *host_b, *host_c, *device_a, *device_b, *device_c;
    host_a = (float*)malloc(size);
    host_b = (float*)malloc(size);
    host_c = (float*)malloc(size);
    for (int i = 0; i < N * N; i++)
    {
        host_a[i] = 1.0f;
        host_b[i] = 1.0f;
    }

    cudaMalloc(&device_a, size);
    cudaMalloc(&device_b, size);
    cudaMalloc(&device_c, size);

    cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(device_b, host_b, size, cudaMemcpyHostToDevice);

    dim3 block(16, 16);
    dim3 grid((N + block.x - 1) / block.x, (N + block.y - 1) / block.y);

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    cudaEventRecord(start);
    mmul_native<<<grid, block>>>(device_a, device_b, device_c, N);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    float ms;
    cudaEventElapsedTime(&ms, start, stop);

    cudaMemcpy(host_c, device_c, size, cudaMemcpyDeviceToHost);

    printf("GPU naive done, host_c[0]=%.1f , time = %.4f\n", host_c[0], ms);

    cudaFree(device_a);
    cudaFree(device_b);
    cudaFree(device_c);

    free(host_a);
    free(host_b);
    free(host_c);

    return 0;
}

```

ç¼–è¯‘ & è¿è¡Œï¼š

```bash
nvcc -O2 mmul_naive.cu -o mmul_naive 
./mmul_naive
```

é¢„æœŸè¾“å‡ºï¼š

![image-20250904201725334](./report_day11.assets/image-20250904201725334.png)

æ€§èƒ½ **æ¯” CPU å¿«æˆç™¾ä¸Šåƒå€**ã€‚

------

### 3. GPU tiled + shared memory

```c++
#include <cuda_runtime.h>
#include <stdio.h>

#define TILE 32

// GPU çŸ©é˜µä¹˜ (Tiled + shared memory)
__global__ void mmul_tiled(const float* a, const float* b, float* c, int N)
{
    __shared__ float a_shared[TILE][TILE];
    __shared__ float b_shared[TILE][TILE];

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    float sum = 0.0f;

    for (int t = 0; t < (N + TILE - 1) / TILE; t++)
    {

        // åŠ è½½ A çš„ä¸€ä¸ªtile
        if (row < N && t * TILE + threadIdx.x < N)
        {
            a_shared[threadIdx.y][threadIdx.x] = a[row * N + t * TILE + threadIdx.x];
        }
        else
        {
            a_shared[threadIdx.y][threadIdx.x] = 0.0f;
        }

        // åŠ è½½ B çš„ä¸€ä¸ªtile
        if (col < N && t * TILE + threadIdx.y < N)
        {
            b_shared[threadIdx.y][threadIdx.x] = b[(t * TILE + threadIdx.y) * N + col];
        }
        else
        {
            b_shared[threadIdx.y][threadIdx.x] = 0.0f;
        }

        __syncthreads();
        // å½“å‰ tile çš„è®¡ç®—
        for (int k = 0; k < TILE; k++)
        {
            sum += a_shared[threadIdx.y][k] * b_shared[k][threadIdx.x];
        }

        __syncthreads();
    }

    // å†™å›ç»“æœ
    if (row < N && col < N)
    {
        c[row * N + col] = sum;
    }
}

int main()
{
    int N = 1024;
    size_t size = N * N * sizeof(float);

    // ä¸»æœºå†…å­˜
    float* host_a = (float*)malloc(size);
    float* host_b = (float*)malloc(size);
    float* host_c = (float*)malloc(size);

    // åˆå§‹åŒ–Aã€B
    for (int i = 0; i < N * N; i++)
    {
        host_a[i] = 1.0f;
        host_b[i] = 1.0f;
    }

    // è®¾å¤‡å†…å­˜
    float *device_a, *device_b, *device_c;
    cudaMalloc((void**)&device_a, size);
    cudaMalloc((void**)&device_b, size);
    cudaMalloc((void**)&device_c, size);

    // æ‹·è´æ•°æ®åˆ° GPU
    cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(device_b, host_b, size, cudaMemcpyHostToDevice);

    // å¯åŠ¨kernel
    dim3 block(TILE, TILE);
    dim3 grid((N + TILE - 1) / TILE, (N + TILE - 1) / TILE);

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    cudaEventRecord(start);
    mmul_tiled<<<grid, block>>>(device_a, device_b, device_c, N);
    cudaEventRecord(stop);

    cudaMemcpy(host_c, device_c, size, cudaMemcpyDeviceToHost);

    cudaEventSynchronize(stop);

    float ms;
    cudaEventElapsedTime(&ms, start, stop);

    printf("N = %d, GPU tiled kernel time = %.3f ms\n", N, ms);
    printf("host_c[0] = %.1f\n", host_c[0]); // éªŒè¯ç»“æœæ­£ç¡®æ€§

    // é‡Šæ”¾èµ„æº
    cudaFree(device_a);
    cudaFree(device_b);
    cudaFree(device_c);
    free(host_a);
    free(host_b);
    free(host_c);

    return 0;
}

```

ç¼–è¯‘ & è¿è¡Œï¼š

```bash
nvcc -O2 mmul_tiled.cu -o mmul_tiled 
./mmul_tiled
```

é¢„æœŸè¾“å‡ºï¼š

![image-20250904210444516](./report_day11.assets/image-20250904210444516.png)

æ€§èƒ½é¢„è®¡ **æ¯” naive kernel è¿˜å†æå‡**ã€‚

------

## 2ï¸âƒ£ æ·±åº¦è¿½é—®

1. **GEMM çš„ç®—å¼º/ç®—å¯†åº¦ä¸ºä½•é€‚åˆ GPUï¼Ÿ**
    å› ä¸º GEMM æ¯æ¬¡åŠ è½½æ•°æ®å¯ä»¥å¤ç”¨å¤šæ¬¡ï¼Œè®¡ç®—é‡ä¸è®¿å­˜é‡æ¯”å€¼é«˜ï¼ˆç®—å¼ºæ¯”é«˜ï¼‰ï¼Œéå¸¸å¥‘åˆ GPU çš„é«˜å¹¶è¡Œç®—åŠ›ã€‚
2. **tiling å°ºå¯¸å¦‚ä½•ä¸ SM ç»“æ„åŒ¹é…ï¼Ÿ**
    tile å¤§å°éœ€è¦ä¸ warp å¤§å°ï¼ˆ32ï¼‰å’Œå…±äº«å†…å­˜å¤§å°å¯¹é½ï¼Œå¸¸ç”¨ TILE=16/32ã€‚è¿‡å¤§å¯¼è‡´å¯„å­˜å™¨/å…±äº«å†…å­˜æº¢å‡ºï¼Œè¿‡å°å¯¼è‡´ç®—åŠ›ä¸è¶³ã€‚
3. **åŒç¼“å†²å¦‚ä½•éšè—è®¿å­˜å»¶è¿Ÿï¼Ÿ**
    é€šè¿‡åœ¨åŠ è½½ä¸‹ä¸€ tile æ—¶å¹¶è¡Œè®¡ç®—å½“å‰ tileï¼Œå®ç°è®¿å­˜/è®¡ç®— overlapã€‚
4. **ä¸ cuBLAS çš„å·®è·æ¥è‡ªå“ªé‡Œï¼Ÿ**
    cuBLAS ç»è¿‡å¤šå¹´ä¼˜åŒ–ï¼ŒåŒ…å« Tensor Coreã€æµæ°´çº¿ã€cache blockingã€å¤šçº¿ç¨‹è°ƒåº¦ç­‰ï¼Œæ‰‹å†™ kernel å¾ˆéš¾å®Œå…¨è¿½å¹³ã€‚
5. **ä¸åŒ N ä¸‹å¤æ‚åº¦çº¿æ€§åº¦éªŒè¯ï¼Ÿ**
    CPU O(NÂ³)ï¼ŒGPU ä¹Ÿ O(NÂ³)ï¼Œä½†å¸¸æ•°é¡¹å’Œå¹¶è¡Œåº¦ä¸åŒã€‚æµ‹è¯•ä¸åŒ N å¯çœ‹åˆ°çº¿æ€§è¶‹åŠ¿ã€‚
6. **æ•°å€¼ç¨³å®šæ€§ä¸æ€§èƒ½çš„å¹³è¡¡ï¼Ÿ**
    FP16 æå‡ååï¼Œä½†ç²¾åº¦ä¸‹é™ï¼›FP32 æ›´ç¨³å®šä½†æ…¢ã€‚å¸¸è§æŠ˜ä¸­æ–¹æ¡ˆæ˜¯ **FP16 è¾“å…¥ï¼ŒFP32 ç´¯åŠ **ã€‚

------

## 3ï¸âƒ£ å®éªŒéƒ¨åˆ†

### ğŸ§ª å®éªŒ 1ï¼šCPU vs GPU vs cuBLAS

#### 1ï¸âƒ£ CPU baseline (`mmul_cpu.cpp`)

å·²ç»å†™è¿‡äº†ï¼Œç›´æ¥ç¼–è¯‘è¿è¡Œï¼š

```bash
g++ -O2 mmul_cpu.cpp -o mmul_cpu
./mmul_cpu
```

------

#### 2ï¸âƒ£ GPU tiled (`mmul_tiled.cu`)

å·²ç»å†™è¿‡äº†ï¼Œç›´æ¥ç¼–è¯‘è¿è¡Œï¼š

```bash
nvcc -O2 mmul_tiled.cu -o mmul_tiled
./mmul_tiled
```

------

#### 3ï¸âƒ£ cuBLAS è°ƒç”¨ (`mmul_cublas.cu`)

```c++
#include <cublas_v2.h>
#include <cuda_runtime.h>
#include <stdio.h>

int main()
{
    int N = 1024;
    size_t size = N * N * sizeof(float);

    float* host_a = (float*)malloc(size);
    float* host_b = (float*)malloc(size);
    float* host_c = (float*)malloc(size);

    for (int i = 0; i < N * N; i++)
    {
        host_a[i] = 1.0f;
        host_b[i] = 1.0f;
    }

    float *device_a, *device_b, *device_c;
    cudaMalloc((void**)&device_a, size);
    cudaMalloc((void**)&device_b, size);
    cudaMalloc((void**)&device_c, size);

    cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(device_b, host_b, size, cudaMemcpyHostToDevice);

    cublasHandle_t handle;
    cublasCreate_v2(&handle);

    float alpha = 1.0f, beta = 0.0f;

    int repeat = 5; // ç»Ÿè®¡ 5 æ¬¡
    float total_ms = 0.0f;

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    // æ’é™¤ç¬¬ä¸€æ¬¡è°ƒç”¨overhead
    cublasSgemm_v2(handle, CUBLAS_OP_N, CUBLAS_OP_N, N, N, N, &alpha, device_b, N, device_a, N,
                   &beta, device_c, N);
    cudaDeviceSynchronize();

    for (int i = 0; i < repeat; i++)
    {
        cudaEventRecord(start);
        cublasSgemm_v2(handle, CUBLAS_OP_N, CUBLAS_OP_N, N, N, N, &alpha, device_b, N, device_a, N,
                       &beta, device_c, N);

        cudaEventRecord(stop);
        cudaEventSynchronize(stop);
        float ms;

        cudaEventElapsedTime(&ms, start, stop);
        total_ms += ms;
    }
    float avg_ms = total_ms / repeat;
    cudaMemcpy(host_c, device_c, size, cudaMemcpyDeviceToHost);

    printf("cuBLAS N=%d, Time: %f ms\n", N, avg_ms);
    printf("host_c[0] = %f\n", host_c[0]);

    cublasDestroy_v2(handle);

    cudaFree(device_a);
    cudaFree(device_b);
    cudaFree(device_c);

    free(host_a);
    free(host_b);
    free(host_c);

    return 0;
}

```

ç¼–è¯‘è¿è¡Œï¼š

```bash
nvcc -lcublas mmul_cublas.cu -o mmul_cublas
./mmul_cublas
```

------

#### 4ï¸âƒ£ å®éªŒæ­¥éª¤

ç¼–è¯‘æ‰€æœ‰ç¨‹åº

```bash
g++ -O2 mmul_cpu.cpp -o mmul_cpu
nvcc -O2 mmul_tiled.cu -o mmul_tiled
nvcc -lcublas mmul_cublas.cu -o mmul_cublas
```

åˆ†åˆ«è¿è¡Œï¼š

```bash
./mmul_cpu
./mmul_tiled
./mmul_cublas
```

------

#### 5ï¸âƒ£ é¢„æœŸç»“æœ

- **CPU**ï¼šè¿è¡Œå‡ ç§’é’Ÿï¼ˆéš NÂ³ å¢é•¿ï¼‰
- **GPU tiled**ï¼šå‡ åæ¯«ç§’
- **cuBLAS**ï¼šæ¯” tiled kernel æ›´å¿«ï¼Œæ¥è¿‘ç†è®ºå³°å€¼

ç»“æœç¤ºä¾‹ï¼ˆN=1024ï¼Œå…·ä½“å–å†³äº GPUï¼‰ï¼š

![image-20250904235355088](./report_day11.assets/image-20250904235355088.png)

------

#### 6ï¸âƒ£ Nsight Compute åˆ†æ

ç”¨ä»¥ä¸‹å‘½ä»¤ profileï¼š

```bash
ncu --kernel-name regex:mmul_tiled ./mmul_tiled
ncu --target-processes all ./mmul_cublas
```

é‡ç‚¹çœ‹æŒ‡æ ‡ï¼š

- **GPU tiled**
  - Global Memory Load Efficiency
  - Shared Memory Utilization
  - Achieved Occupancy
- **cuBLAS**
  - Tensor Core ä½¿ç”¨æƒ…å†µ
  - FLOP efficiency
  - Memory throughput

------

### ğŸ§ª å®éªŒ 2ï¼šTile å¤§å°è°ƒå‚

#### 1ï¸âƒ£ å‡†å¤‡ä»£ç 

å®Œæ•´ä»£ç ä¹‹å‰å·²ç»æœ‰äº†ï¼ˆ`mmul_tiled.cu`ï¼‰ã€‚

------

#### 2ï¸âƒ£ ç¼–è¯‘ä¸åŒ TILE å¤§å°çš„ç‰ˆæœ¬

åœ¨å‘½ä»¤è¡Œç”¨ `-D` åŠ¨æ€ä¿®æ”¹ TILEï¼š

```bash
nvcc -O2 -DTILE=16 mmul_tiled.cu -o tiled16
nvcc -O2 -DTILE=32 mmul_tiled.cu -o tiled32
nvcc -O2 -DTILE=64 mmul_tiled.cu -o tiled64
```

------

#### 3ï¸âƒ£ è¿è¡Œå¹¶è®°å½•æ—¶é—´

```bash
./tiled16
./tiled32
./tiled64
```

è¾“å‡ºï¼š

![image-20250905001705235](./report_day11.assets/image-20250905001705235.png)

------

#### 4ï¸âƒ£ ç»“æœåˆ†æ

- **TILE=16**ï¼šè®¡ç®—é‡å°ï¼Œè®¿å­˜æ¯”ä¾‹é«˜ï¼Œæ€§èƒ½å·®ã€‚
- **TILE=32**ï¼šè®¿å­˜/ç®—åŠ›æ¯”è¾ƒå‡è¡¡ï¼Œé€šå¸¸æ˜¯ç»å…¸æœ€ä¼˜é€‰æ‹©ã€‚
- **TILE=64**ï¼šåœ¨æ–°çš„ç¡¬ä»¶ & N=1024 çš„æƒ…å†µä¸‹ï¼Œç®—å¼ºæ¯”æ›´é«˜ã€è®¿å­˜å¯¹é½æ›´å¥½ï¼Œæ‰€ä»¥æ¯” TILE=32 æ›´å¿«ã€‚

------

#### 5ï¸âƒ£ ç”¨ Nsight Compute éªŒè¯

è¿è¡Œï¼š

```bash
ncu --kernel-name regex:mmul_tiled ./tiled16
ncu --kernel-name regex:mmul_tiled ./tiled32
ncu --kernel-name regex:mmul_tiled ./tiled64
```

é‡ç‚¹çœ‹ï¼š

- **Shared Memory Utilization**
- **Achieved Occupancy**
- **Memory Throughput**

------

### ğŸ§ª å®éªŒ 3ï¼šåŒç¼“å†²ä¼˜åŒ–

#### 1ï¸âƒ£ èƒŒæ™¯

æ™®é€šçš„ Tiled GEMMï¼š

- æ¯æ¬¡è¿­ä»£ï¼šå…ˆ `load` Aã€B tile â†’ `__syncthreads()` â†’ å† `compute`ã€‚
- è®¿å­˜å’Œè®¡ç®—æ˜¯ **ä¸²è¡Œ** çš„ï¼ŒSM åœ¨ç­‰å¾… global memory çš„æ—¶å€™ pipeline ç©ºé—²ã€‚

**åŒç¼“å†² (double buffering)ï¼š**

- åˆ†é…ä¸¤ä¸ª `__shared__` tileï¼ˆA1/A2, B1/B2ï¼‰ã€‚
- åœ¨è®¡ç®— tile i çš„æ—¶å€™ï¼Œå°±é¢„å– tile i+1 åˆ°å¦ä¸€ä¸ª bufferã€‚
- è¿™æ ·å¯ä»¥ **overlap global memory load å’Œè®¡ç®—**ï¼Œå‡å°‘ stallã€‚

------

#### 2ï¸âƒ£ CUDA åŒç¼“å†²å®ç°

```c++
#include <cuda_runtime.h>
#include <stdio.h>

#define TILE 32

// åŒç¼“å†² GEMM kernel
__global__ void mmul_tiled_double_buffer(const float* A, const float* B, float* C, int N)
{
    __shared__ float a_shared[2][TILE][TILE];
    __shared__ float b_shared[2][TILE][TILE];

    int row = blockIdx.y * TILE + threadIdx.y;
    int col = blockIdx.x * TILE + threadIdx.x;
    float sum = 0.0f;

    int buf = 0;

    // é¢„åŠ è½½ç¬¬ 0 å¿«tile
    if (row < N && threadIdx.x < TILE)
    {
        a_shared[buf][threadIdx.y][threadIdx.x] = A[row * N + threadIdx.x];
    }
    else
    {
        a_shared[buf][threadIdx.y][threadIdx.x] = 0.0f;
    }
    if (col < N && threadIdx.y < TILE)
    {
        b_shared[buf][threadIdx.y][threadIdx.x] = B[threadIdx.y * N + col];
    }
    else
    {
        b_shared[buf][threadIdx.y][threadIdx.x] = 0.0f;
    }

    __syncthreads();

    // éå†æ‰€æœ‰tile
    for (int t = 0; t < (N + TILE - 1) / TILE; t++)
    {
        int next = (buf + 1) % 2;

        // æå‰é¢„å–ä¸‹ä¸€ä¸ª tile
        if (t + 1 < (N + TILE - 1) / TILE)
        {
            if (row < N && (t + 1) * TILE + threadIdx.x < N)
            {
                a_shared[next][threadIdx.y][threadIdx.x] =
                    A[row * N + (t + 1) * TILE + threadIdx.x];
            }
            else
            {
                a_shared[next][threadIdx.y][threadIdx.x] = 0.0f;
            }

            if (col < N && (t + 1) * TILE + threadIdx.y < N)
            {
                b_shared[next][threadIdx.y][threadIdx.x] =
                    B[((t + 1) * TILE + threadIdx.y) * N + col];
            }
            else
            {
                b_shared[next][threadIdx.y][threadIdx.x] = 0.0f;
            }
        }
        for (int k = 0; k < TILE; k++)
        {
            sum += a_shared[buf][threadIdx.y][k] * b_shared[buf][k][threadIdx.x];
        }

        __syncthreads();
        buf = next;
    }
    if (row < N && col < N)
    {
        C[row * N + col] = sum;
    }
}

int main()
{
    int N = 1024; // çŸ©é˜µå¤§å°
    size_t size = N * N * sizeof(float);

    // åˆ†é…ä¸»æœºå†…å­˜
    float* host_a = (float*)malloc(size);
    float* host_b = (float*)malloc(size);
    float* host_c = (float*)malloc(size);

    // åˆå§‹åŒ–
    for (int i = 0; i < N * N; i++)
    {
        host_a[i] = 1.0f;
        host_b[i] = 1.0f;
    }

    // åˆ†é…è®¾å¤‡å†…å­˜
    float *device_a, *device_b, *device_c;
    cudaMalloc((void**)&device_a, size);
    cudaMalloc((void**)&device_b, size);
    cudaMalloc((void**)&device_c, size);

    cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(device_b, host_b, size, cudaMemcpyHostToDevice);

    // é…ç½®kernel
    dim3 block(TILE, TILE);
    dim3 grid((N + TILE - 1) / TILE, (N + TILE - 1) / TILE);

    // è®¡æ—¶
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    cudaEventRecord(start);
    mmul_tiled_double_buffer<<<grid, block>>>(device_a, device_b, device_c, N);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    float ms;
    cudaEventElapsedTime(&ms, start, stop);

    cudaMemcpy(host_c, device_c, size, cudaMemcpyDeviceToHost);

    // è¾“å‡ºç»“æœ
    printf("N = %d, GPU double buffer kernel time = %.3f ms\n", N, ms);
    printf("C[0] = %.1f\n", host_c[0]);

    // æ¸…ç†
    cudaFree(device_a);
    cudaFree(device_b);
    cudaFree(device_c);

    free(host_a);
    free(host_b);
    free(host_c);

    return 0;
}

```

------

#### 3ï¸âƒ£ ç¼–è¯‘ & è¿è¡Œ

```bash
nvcc -O2 mmul_tiled_double_buffer.cu -o mmul_db
./mmul_db
```

è¾“å‡ºç¤ºä¾‹ï¼š

![image-20250905024811139](./report_day11.assets/image-20250905024811139.png)

------

#### 4ï¸âƒ£ å¯¹æ¯”ç»“æœ

- æ™®é€š tiled (TILE=32): ~1.39 ms
- åŒç¼“å†² tiled: ~1.203 ms
- **æœ‰æ‰€åŠ é€Ÿ**

------

#### 5ï¸âƒ£ Nsight Compute éªŒè¯

```bash
ncu --kernel-name regex:mmul_tiled_double_buffer ./mmul_db
```

é‡ç‚¹è§‚å¯ŸæŒ‡æ ‡ï¼š

- **Warp Stall Reasons** â†’ Memory Dependencyï¼ˆåº”æ˜¾è‘—ä¸‹é™ï¼‰
- **Memory Pipe Busy** â†’ æ›´å‡åŒ€
- **SM Busy** â†’ æå‡ï¼Œè¯´æ˜è®¡ç®—å•å…ƒæ›´é¥±å’Œ

------

#### âœ… å®éªŒç»“è®º

- åŒç¼“å†²æŠ€æœ¯æˆåŠŸå®ç°äº† **è®¿å­˜å’Œè®¡ç®— overlap**ã€‚
- æ€§èƒ½æå‡ **10-20%**ï¼Œå…·ä½“å–å†³äºç¡¬ä»¶çš„ **è®¿å­˜å»¶è¿Ÿ / å¸¦å®½**ã€‚
- åœ¨æ›´å¤§è§„æ¨¡ GEMMã€Tensor Core kernel ä¸­æ•ˆæœæ›´æ˜æ˜¾ã€‚

------

### ğŸ§ª å®éªŒ 4ï¼šFP16 vs FP32

#### ğŸ¯ å®éªŒç›®æ ‡

- æ¯”è¾ƒ **FP32 å…¨ç¨‹** vs **FP16 è¾“å…¥ + FP32 ç´¯åŠ ** çš„æ€§èƒ½ä¸ç²¾åº¦å·®å¼‚ã€‚
- éªŒè¯ GPU ä¸Š **åŠç²¾åº¦èƒ½æå‡ååï¼Œä½†å¯èƒ½å¸¦æ¥ç²¾åº¦æŸå¤±**ã€‚

------

#### 1ï¸âƒ£ æ€è·¯è®²è§£

1. **è®¿å­˜å¸¦å®½ç“¶é¢ˆ**
    GEMM å¾€å¾€å—é™äºè®¿å­˜ï¼ŒFP16 è¾“å…¥å¯è®©å†…å­˜å¸¦å®½å ç”¨å‡åŠ â†’ æ›´å¿«ã€‚
2. **æ•°å€¼ç²¾åº¦**
   - FP16ï¼šå­˜å‚¨å’ŒåŠ è½½æ—¶æ›´ç´§å‡‘ï¼ŒåŠ¨æ€èŒƒå›´å°ï¼Œç´¯ç§¯è¯¯å·®å¤§ã€‚
   - FP32 ç´¯åŠ ï¼šç”¨ 32 ä½æµ®ç‚¹å­˜å‚¨ä¸­é—´ç»“æœï¼Œå‡å°‘æº¢å‡ºå’Œç´¯ç§¯è¯¯å·®ã€‚
3. **CUDA å®ç°**
   - ä½¿ç”¨ `__half`ï¼ˆæ¥è‡ª `<cuda_fp16.h>`ï¼‰ã€‚
   - è½¬æ¢ï¼š`__half2float` æŠŠåŠç²¾åº¦è½¬ floatï¼›`__float2half` æŠŠ float è½¬åŠç²¾åº¦ã€‚
   - kernel ä¸­ï¼š
     - Aã€B ç”¨ FP16 å­˜å‚¨ã€åŠ è½½ã€‚
     - C ç”¨ FP32 å­˜å‚¨ï¼Œç´¯åŠ åœ¨ FP32ã€‚

------

#### 2ï¸âƒ£ å®Œæ•´ä»£ç 

ä¿å­˜ä¸º `mmul_fp16_vs_fp32.cu`ï¼š

```c++
#include <cuda_runtime.h>
#include <cuda_fp16.h>   // FP16 æ”¯æŒ
#include <stdio.h>

#define TILE 16

// FP32 baseline kernel
__global__ void mmul_fp32(const float* A, const float* B, float* C, int N) {
    int row = blockIdx.y * TILE + threadIdx.y;
    int col = blockIdx.x * TILE + threadIdx.x;
    float sum = 0.0f;

    if (row < N && col < N) {
        for (int k = 0; k < N; k++) {
            sum += A[row * N + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}

// FP16 è¾“å…¥ + FP32 ç´¯åŠ  kernel
__global__ void mmul_fp16_acc32(const __half* A, const __half* B, float* C, int N) {
    int row = blockIdx.y * TILE + threadIdx.y;
    int col = blockIdx.x * TILE + threadIdx.x;
    float sum = 0.0f;

    if (row < N && col < N) {
        for (int k = 0; k < N; k++) {
            // WHY: åŠç²¾åº¦åŠ è½½ï¼Œå†è½¬ä¸º float åšä¹˜åŠ ï¼Œé¿å…ç´¯ç§¯ç²¾åº¦æŸå¤±
            float a_val = __half2float(A[row * N + k]);
            float b_val = __half2float(B[k * N + col]);
            sum += a_val * b_val;
        }
        C[row * N + col] = sum;
    }
}

int main() {
    int N = 512; // çŸ©é˜µå¤§å°ï¼ˆè°ƒå¤§å¯è§‚å¯Ÿæ€§èƒ½å·®å¼‚ï¼‰
    size_t size_f32 = N * N * sizeof(float);
    size_t size_f16 = N * N * sizeof(__half);

    // ä¸»æœºå†…å­˜
    float* h_A = (float*)malloc(size_f32);
    float* h_B = (float*)malloc(size_f32);
    float* h_C_fp32 = (float*)malloc(size_f32);
    float* h_C_fp16 = (float*)malloc(size_f32);

    // åˆå§‹åŒ–æ•°æ®
    for (int i = 0; i < N * N; i++) {
        h_A[i] = (float)(i % 3 + 1); // ä¸€äº›å°æ•´æ•°
        h_B[i] = (float)(i % 5 + 1);
    }

    // è®¾å¤‡å†…å­˜
    float *d_A_f32, *d_B_f32, *d_C_fp32;
    __half *d_A_f16, *d_B_f16;
    float *d_C_fp16;

    cudaMalloc(&d_A_f32, size_f32);
    cudaMalloc(&d_B_f32, size_f32);
    cudaMalloc(&d_C_fp32, size_f32);

    cudaMalloc(&d_A_f16, size_f16);
    cudaMalloc(&d_B_f16, size_f16);
    cudaMalloc(&d_C_fp16, size_f32);

    // æ‹·è´ FP32 è¾“å…¥
    cudaMemcpy(d_A_f32, h_A, size_f32, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B_f32, h_B, size_f32, cudaMemcpyHostToDevice);

    // å°† FP32 è½¬æ¢ä¸º FP16 å¹¶æ‹·è´
    __half* h_A_f16 = (__half*)malloc(size_f16);
    __half* h_B_f16 = (__half*)malloc(size_f16);
    for (int i = 0; i < N * N; i++) {
        h_A_f16[i] = __float2half(h_A[i]);
        h_B_f16[i] = __float2half(h_B[i]);
    }
    cudaMemcpy(d_A_f16, h_A_f16, size_f16, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B_f16, h_B_f16, size_f16, cudaMemcpyHostToDevice);

    // kernel é…ç½®
    dim3 block(TILE, TILE);
    dim3 grid((N + TILE - 1) / TILE, (N + TILE - 1) / TILE);

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    // ==== FP32 baseline ====
    cudaEventRecord(start);
    mmul_fp32<<<grid, block>>>(d_A_f32, d_B_f32, d_C_fp32, N);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    float ms_fp32;
    cudaEventElapsedTime(&ms_fp32, start, stop);
    cudaMemcpy(h_C_fp32, d_C_fp32, size_f32, cudaMemcpyDeviceToHost);

    // ==== FP16 è¾“å…¥ + FP32 ç´¯åŠ  ====
    cudaEventRecord(start);
    mmul_fp16_acc32<<<grid, block>>>(d_A_f16, d_B_f16, d_C_fp16, N);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    float ms_fp16;
    cudaEventElapsedTime(&ms_fp16, start, stop);
    cudaMemcpy(h_C_fp16, d_C_fp16, size_f32, cudaMemcpyDeviceToHost);

    // ç»“æœå¯¹æ¯”
    printf("Matrix N=%d\n", N);
    printf("FP32 kernel time = %.3f ms\n", ms_fp32);
    printf("FP16 input + FP32 accumulate kernel time = %.3f ms\n", ms_fp16);
    printf("C[0] FP32=%.2f, FP16+FP32=%.2f\n", h_C_fp32[0], h_C_fp16[0]);

    // ç®€å•è¯¯å·®æ£€æŸ¥
    double diff = 0.0;
    for (int i = 0; i < N * N; i++) {
        diff += fabs(h_C_fp32[i] - h_C_fp16[i]);
    }
    printf("Total abs diff = %.3f\n", diff);

    // é‡Šæ”¾
    free(h_A); free(h_B); free(h_C_fp32); free(h_C_fp16);
    free(h_A_f16); free(h_B_f16);
    cudaFree(d_A_f32); cudaFree(d_B_f32); cudaFree(d_C_fp32);
    cudaFree(d_A_f16); cudaFree(d_B_f16); cudaFree(d_C_fp16);

    return 0;
}
```

------

#### 3ï¸âƒ£ ç¼–è¯‘ & è¿è¡Œ

```
nvcc -O2 mmul_fp16_vs_fp32.cu -o mmul_fp16_vs_fp32
./mmul_fp16_vs_fp32
```

è¾“å‡ºï¼š

![image-20250905045721370](./report_day11.assets/image-20250905045721370.png)

------

#### 4ï¸âƒ£ Profiling æŒ‡å¯¼

è¿è¡Œ Nsight Computeï¼š

```
ncu --kernel-name regex:mmul_fp16_acc32 ./mmul_fp16_vs_fp32
```

è§‚å¯ŸæŒ‡æ ‡ï¼š

- **Memory Throughput** â†’ FP16 è®¿å­˜åº”æ˜æ˜¾ä¸‹é™
- **SM Busy** â†’ æ›´é¥±å’Œ
- **Instruction Mix** â†’ FP16 load/store, FP32 FMA
- **Accuracy æ£€æŸ¥** â†’ diff è¶Šå¤§ï¼Œè¯´æ˜ FP16 ç²¾åº¦æŸå¤±æ›´æ˜æ˜¾

------

#### 5ï¸âƒ£ é¢„æœŸç»“æœ

- **æ€§èƒ½**ï¼šFP16 è¾“å…¥ + FP32 ç´¯åŠ æ¯” FP32 baseline å¿« **20-40%**ï¼Œå–å†³äºçŸ©é˜µå¤§å°å’Œ GPU æ¶æ„ã€‚
- **ç²¾åº¦**ï¼šç»“æœæœ‰ä¸€å®šåå·®ï¼Œä½†åœ¨å¤šæ•°æ·±åº¦å­¦ä¹ åœºæ™¯å¯æ¥å—ã€‚
- **æœ€ä½³å®è·µ**ï¼šå¤§éƒ¨åˆ† DL æ¡†æ¶é»˜è®¤é‡‡ç”¨ **æ··åˆç²¾åº¦ (AMP: Automatic Mixed Precision)**ï¼Œå³ FP16 è¾“å…¥ + FP32 ç´¯åŠ ã€‚

------

### ğŸ§ª å®éªŒ 5ï¼šNsight åˆ†æç“¶é¢ˆ

#### ğŸ¯ å®éªŒç›®æ ‡

- ç”¨ Nsight å·¥å…·åˆ†æçŸ©é˜µä¹˜æ³• kernel (`mmul_tiled` æˆ– `mmul_tiled_double_buffer`) çš„æ€§èƒ½ç“¶é¢ˆã€‚
- è§‚å¯Ÿ **Warp divergenceã€è®¿å­˜å¸¦å®½ã€å…±äº«å†…å­˜åˆ©ç”¨ç‡** ç­‰æŒ‡æ ‡ï¼Œåˆ¤æ–­ä¼˜åŒ–æ–¹å‘ã€‚

------

#### 1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡

ç¡®è®¤å·²å®‰è£… Nsight å·¥å…·ï¼ˆCUDA Toolkit è‡ªå¸¦ï¼‰ï¼š

```bash
which nsys
which ncu
```

å¦‚æœæ²¡æœ‰ï¼Œå®‰è£… CUDA Toolkit æ—¶éœ€è¦å‹¾é€‰ Nsight Compute / Nsight Systemsã€‚

------

#### 2ï¸âƒ£ è¿è¡Œ Nsight Systems (å…¨å±€åˆ†æ)

`nsys` ä¸»è¦çœ‹ **æ•´ä½“ timeline**ï¼ˆCPU/GPU è°ƒåº¦ã€kernel è°ƒç”¨ã€å†…å­˜ä¼ è¾“ï¼‰ã€‚

è¿è¡Œï¼š

```bash
nsys profile -o mmul_tiled_report ./mmul_tiled
```

ç”ŸæˆæŠ¥å‘Šï¼š`mmul_tiled_report.qdrep`

æŸ¥çœ‹æŠ¥å‘Šï¼š

æ²¡æœ‰guiç•Œé¢å¯å‘é€åˆ°å®¿ä¸»æœºç”¨ ncu/nsys æŸ¥çœ‹

```bash
nsys-ui mmul_tiled_report.qdrep
```

é‡ç‚¹å…³æ³¨ï¼š

- **GPU Context Timeline**ï¼škernel å¯åŠ¨æ˜¯å¦æœ‰ idle æ—¶é—´ã€‚
- **Memcpy vs Compute**ï¼šæ•°æ®æ‹·è´æ˜¯å¦æˆä¸ºç“¶é¢ˆã€‚
- **Kernel Duration**ï¼šå„ kernel çš„æ‰§è¡Œæ—¶é—´åˆ†å¸ƒã€‚

------

#### 3ï¸âƒ£ è¿è¡Œ Nsight Compute (æ·±å…¥ kernel)

`ncu` ä¸»è¦çœ‹ **å•ä¸ª kernel çš„ç¡¬ä»¶æŒ‡æ ‡**ã€‚

è¿è¡Œï¼š

```bash
ncu --set full --kernel-name regex:mmul_tiled ./mmul_tiled
```

æˆ–æŒ‡å®šæ›´è¯¦ç»†çš„ metricï¼š

```bash
ncu --metrics \
sm__warps_active.avg.pct_of_peak_sustained_active,\
sm__warp_divergence_rate.pct,\
dram__throughput.avg.pct_of_peak_sustained_elapsed,\
shared_load_throughput,\
shared_store_throughput \
./mmul_tiled
```

------

#### 4ï¸âƒ£ å…³æ³¨æŒ‡æ ‡è§£è¯»

1. **Warp divergence < 5%**
   - è¯´æ˜å¤§éƒ¨åˆ†çº¿ç¨‹æ‰§è¡Œè·¯å¾„ä¸€è‡´ï¼Œwarp æ²¡æœ‰å¤§é‡åˆ†æ”¯æµªè´¹ã€‚
   - å¦‚æœ divergence > 20%ï¼Œè¦æ£€æŸ¥æ¡ä»¶åˆ†æ”¯æˆ–çº¿ç¨‹å—è¾¹ç•Œå¤„ç†ã€‚
2. **Memory throughput æ¥è¿‘ç†è®ºå¸¦å®½**
   - æŒ‡æ ‡ï¼š`dram__throughput`
   - å¦‚æœåªç”¨åˆ°å³°å€¼çš„ 30-40%ï¼Œè¯´æ˜è®¿å­˜æ¨¡å¼ä¸ä½³ï¼ˆæœª coalescedã€bank conflictï¼‰ã€‚
   - å¯¹æ¯” FP32 vs FP16 æ—¶ï¼ŒFP16 ç‰ˆæœ¬åååº”æ›´ä½ï¼Œä½†ç®—åŠ›åˆ©ç”¨ç‡æ›´é«˜ã€‚
3. **Shared memory utilization > 80%**
   - æŒ‡æ ‡ï¼š`shared_load_throughput` / `shared_store_throughput`
   - å¦‚æœ < 50%ï¼Œè¯´æ˜å…±äº«å†…å­˜ tile æ²¡è¢«å……åˆ†å¤ç”¨ï¼Œè¦æ£€æŸ¥ tile å¤§å°å’Œæ•°æ®å¤ç”¨ç‡ã€‚
4. **SM Busy > 80%**
   - æŒ‡æ ‡ï¼š`sm__warps_active.avg.pct_of_peak_sustained_active`
   - è¯´æ˜ GPU è®¡ç®—å•å…ƒåŸºæœ¬åƒæ»¡äº†ã€‚
   - å¦‚æœåªæœ‰ 40-50%ï¼Œè¯´æ˜ kernel å—é™äºè®¿å­˜æˆ–è°ƒåº¦ã€‚

------

#### 5ï¸âƒ£ ç°è±¡

- **æ™®é€š tiled GEMM**ï¼š
  - Warp divergence ~ 0-2%ï¼ˆåŸºæœ¬æ²¡æœ‰åˆ†æ”¯ï¼‰ã€‚
  - Memory throughput ~ 40-60% å³°å€¼ï¼ˆå—è®¿å­˜é™åˆ¶ï¼‰ã€‚
  - Shared memory utilization ~ 70%ã€‚
  - SM Busy ~ 50-60%ã€‚
- **åŒç¼“å†² GEMM**ï¼š
  - Warp divergence ä»ç„¶ ~ 0-2%ã€‚
  - Memory throughput æ›´å¹³æ»‘ï¼ˆè®¿å­˜/è®¡ç®— overlapï¼‰ã€‚
  - Shared memory utilization â†‘ï¼ˆæ›´é«˜é‡ç”¨ç‡ï¼‰ã€‚
  - SM Busy â†‘ åˆ° 70-80%ã€‚

------

#### 6ï¸âƒ£ ç»“è®º

- æ™®é€š tiled kernel å— **è®¿å­˜å¸¦å®½é™åˆ¶**ï¼ŒSM Busy è¾ƒä½ã€‚
- åŒç¼“å†²ä¼˜åŒ–åï¼Œ**è®¿å­˜ä¸è®¡ç®— overlap**ï¼ŒMemory Pipe æ›´å‡åŒ€ï¼ŒSM Busy æ˜æ˜¾æå‡ã€‚
- ä¸‹ä¸€æ­¥å¯å°è¯• **æ··åˆç²¾åº¦ (FP16+FP32)** æˆ– **Tensor Core (WMMA API)**ï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

------

## âœ… æ€»ç»“

1. CPU çŸ©é˜µä¹˜æ³• O(NÂ³)ï¼Œåœ¨ N=1024 æ—¶å·²ä¸å¯ç”¨ã€‚
2. GPU naive kernel å·²å¤§å¹…æé€Ÿï¼Œä½†è®¿å­˜æ•ˆç‡ä½ã€‚
3. Shared memory tiling è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œæ˜¾è‘—å‡å°‘ global memory è®¿é—®ã€‚
4. Tile å°ºå¯¸å¯¹æ€§èƒ½å½±å“æå¤§ï¼Œéœ€è¦ç»“åˆç¡¬ä»¶å…±äº«å†…å­˜/å¯„å­˜å™¨é™åˆ¶è°ƒä¼˜ã€‚
5. åŒç¼“å†²èƒ½éšè—è®¿å­˜å»¶è¿Ÿï¼Œæé«˜ç®—åŠ›åˆ©ç”¨ç‡ã€‚
6. FP16 è¾“å…¥ + FP32 ç´¯åŠ åœ¨æ€§èƒ½ä¸ç²¾åº¦ä¹‹é—´è¾¾åˆ°å¹³è¡¡ã€‚
7. ä¸ cuBLAS ç›¸æ¯”ï¼Œè‡ªå®ç° kernel ä»æœ‰å·®è·ï¼Œä½†é€šè¿‡ profiling å­¦ä¹ äº† GPU ä¼˜åŒ–æ€è·¯ã€‚