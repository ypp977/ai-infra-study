# â˜¸ï¸ AI æ¨ç†å¹³å° â€” Kubernetes éƒ¨ç½²å®Œæ•´æ•™ç¨‹

## 1ï¸âƒ£ å‰ç½®å‡†å¤‡

### (1) ç¯å¢ƒè¦æ±‚

- ä¸€å°æ”¯æŒ NVIDIA GPU çš„æœåŠ¡å™¨ï¼ˆUbuntu 20.04/22.04ï¼‰
- å·²å®‰è£…ï¼š
  - **Docker**
  - **NVIDIA Container Toolkit** (`nvidia-docker2`)
  - **Kubernetes (kubectl + minikube æˆ– kind)**
  - **helm**

æ£€æŸ¥ GPUï¼š

```bash
nvidia-smi
```

âœ… è¾“å‡ºæ˜¾å¡ä¿¡æ¯ã€‚

æ£€æŸ¥ Kubernetesï¼š

```bash
kubectl get nodes
```

âœ… è‡³å°‘æœ‰ä¸€ä¸ª `Ready` èŠ‚ç‚¹ã€‚

------

### (2) å®‰è£… GPU æ’ä»¶

K8s éœ€è¦ GPU device plugin æ‰èƒ½è°ƒåº¦ GPU Podï¼š

```bash
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.0/nvidia-device-plugin.yml
```

æ£€æŸ¥æ˜¯å¦æˆåŠŸï¼š

```bash
kubectl get pods -n kube-system | grep nvidia
```

âœ… çœ‹åˆ° `nvidia-device-plugin-daemonset-xxxxx` çŠ¶æ€æ˜¯ `Running`ã€‚

------

## 2ï¸âƒ£ åœ¨ Docker ä¸­å‡†å¤‡æ¨¡å‹

### 1.å¯åŠ¨å¼€å‘å®¹å™¨

é¦–å…ˆå¯åŠ¨ä¸€ä¸ªå¸¦ GPU çš„ PyTorch å®¹å™¨ï¼ˆé‡Œé¢åŒ…å« Python, CUDA, PyTorchï¼‰ï¼š

```dockerfile
FROM nvcr.io/nvidia/pytorch:23.05-py3

# å®‰è£… ONNX / TensorRT / Triton Client
RUN pip install --upgrade pip \
 && pip install onnx onnxruntime-gpu tritonclient[all] tensorrt

WORKDIR /workspace
COPY . /workspace

CMD ["/bin/bash"]
```

åˆ›å»ºé•œåƒå¹¶æ‰§è¡Œå®¹å™¨

```bash
docker build -t my-ai-infer:latest .
docker run --gpus all -it -v $PWD:/workspace my-ai-infer:latest
```

### 2.å‡†å¤‡ä¸¤ä¸ªæ¨¡å‹ï¼š

- **MNIST (ONNX)**
- **ResNet50 (TensorRT)**

ç›®å½•ï¼š

```bash
ai-infra-inference-service/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_mnist.py
â”‚   â”œâ”€â”€ export_mnist.py
â”‚   â”œâ”€â”€ export_resnet50.py
â”‚   â””â”€â”€ prepare_models.sh
â”œâ”€â”€ onnx/
â”œâ”€â”€ tensorrt/
â””â”€â”€ triton/
```

------

#### (1) è®­ç»ƒ MNIST

```python
# scripts/train_mnist.py
import torch, torch.nn as nn, torch.optim as optim
import torchvision, torchvision.transforms as transforms

# æ•°æ®é›†
transform = transforms.Compose([transforms.ToTensor()])
trainset = torchvision.datasets.MNIST("./data", train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

# æ¨¡å‹
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 10)
    def forward(self, x):
        x = x.view(-1, 28*28)
        return self.fc2(torch.relu(self.fc1(x)))

model = MLP()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒ
for epoch in range(1):
    for imgs, labels in trainloader:
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
print("è®­ç»ƒå®Œæˆï¼Œloss:", loss.item())
torch.save(model.state_dict(), "mlp.pth")
```

#### (2) å¯¼å‡º MNIST ONNX

```python
# scripts/export_mnist.py
import torch, torch.nn as nn

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 10)
    def forward(self, x):
        x = x.view(-1, 28*28)
        return self.fc2(torch.relu(self.fc1(x)))

model = MLP()
model.load_state_dict(torch.load("mlp.pth"))
model.eval()

dummy = torch.randn(1, 1, 28, 28)
torch.onnx.export(model, dummy, "onnx/mnist.onnx",
                  input_names=["input"], output_names=["output"],
                  dynamic_axes={"input": {0: "batch"}, "output": {0: "batch"}})
print("MNIST å¯¼å‡ºå®Œæˆ: onnx/mnist.onnx")
```

------

#### (3) å¯¼å‡º ResNet50 ONNX

```python
# scripts/export_resnet50.py
import torch, torchvision

model = torchvision.models.resnet50(pretrained=True)
model.eval()

dummy = torch.randn(1, 3, 224, 224)
torch.onnx.export(model, dummy, "onnx/resnet50.onnx",
                  input_names=["input"], output_names=["output"],
                  dynamic_axes={"input": {0: "batch"}, "output": {0: "batch"}})
print("ResNet50 å¯¼å‡ºå®Œæˆ: onnx/resnet50.onnx")
```

#### (4) è½¬æ¢ TensorRT Engine

```bash
trtexec \
  --onnx=$ONNX_DIR/mnist.onnx \
  --saveEngine=$TRT_DIR/mnist_fp16.engine \
  --fp16 \
  --minShapes=input:1x1x28x28 \
  --optShapes=input:4x1x28x28 \
  --maxShapes=input:8x1x28x28 \
  --explicitBatch \
  > $TRT_DIR/mnist_build.log 2>&1
trtexec \
  --onnx=$ONNX_DIR/resnet50.onnx \
  --saveEngine=$TRT_DIR/resnet50_fp16.engine \
  --fp16 \
  --minShapes=input:1x3x224x224 \
  --optShapes=input:8x3x224x224 \
  --maxShapes=input:16x3x224x224 \
  --explicitBatch \
  > $TRT_DIR/resnet50_build.log 2>&1
```

#### (5) ç»„ç»‡ Triton æ¨¡å‹ä»“åº“

```bash
triton/
â”œâ”€â”€ mnist_mlp/
â”‚   â”œâ”€â”€ 1/model.onnx
â”‚   â””â”€â”€ config.pbtxt
â””â”€â”€ resnet50/
    â”œâ”€â”€ 1/model.plan
    â””â”€â”€ config.pbtxt
```

#### (6) ä¸€é”®å‡†å¤‡æ¨¡å‹

```python
#!/bin/bash
set -e

# =============== è·¯å¾„é…ç½® ===============
ROOT_DIR=$(dirname $(readlink -f "$0"))/..
ONNX_DIR=$ROOT_DIR/onnx
TRT_DIR=$ROOT_DIR/tensorrt
TRITON_DIR=$ROOT_DIR/triton

mkdir -p $ONNX_DIR $TRT_DIR $TRITON_DIR

echo "ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: $ROOT_DIR"
echo "ğŸ“‚ ONNX ç›®å½•: $ONNX_DIR"
echo "ğŸ“‚ TensorRT Engine ç›®å½•: $TRT_DIR"
echo "ğŸ“‚ Triton æ¨¡å‹ä»“åº“: $TRITON_DIR"

# =============== 1. è®­ç»ƒ MNIST ===============
echo "ğŸ“ è®­ç»ƒ MNIST æ¨¡å‹..."
python $ROOT_DIR/scripts/train_mnist.py

# =============== 2. å¯¼å‡º MNIST ONNX ===============
echo "ğŸ“¦ å¯¼å‡º MNIST ONNX..."
python $ROOT_DIR/scripts/export_mnist.py

# =============== 3. å¯¼å‡º ResNet50 ONNX ===============
echo "ğŸ“¦ å¯¼å‡º ResNet50 ONNX..."
python $ROOT_DIR/scripts/export_resnet50.py

# =============== 4. è½¬æ¢ TensorRT Engineï¼ˆæ”¯æŒåŠ¨æ€ batchï¼‰ ===============
echo "âš¡ è½¬æ¢ TensorRT Engine (FP16 + åŠ¨æ€ Batch)..."

# MNIST Engine: batch 1~8
trtexec \
  --onnx=$ONNX_DIR/mnist.onnx \
  --saveEngine=$TRT_DIR/mnist_fp16.engine \
  --fp16 \
  --minShapes=input:1x1x28x28 \
  --optShapes=input:4x1x28x28 \
  --maxShapes=input:8x1x28x28 \
  --explicitBatch \
  > $TRT_DIR/mnist_build.log 2>&1

# ResNet50 Engine: batch 1~16
trtexec \
  --onnx=$ONNX_DIR/resnet50.onnx \
  --saveEngine=$TRT_DIR/resnet50_fp16.engine \
  --fp16 \
  --minShapes=input:1x3x224x224 \
  --optShapes=input:8x3x224x224 \
  --maxShapes=input:16x3x224x224 \
  --explicitBatch \
  > $TRT_DIR/resnet50_build.log 2>&1

echo "âœ… TensorRT Engine å·²ç”Ÿæˆ: $TRT_DIR/*.engine"

# =============== 5. æ„å»º Triton æ¨¡å‹ä»“åº“ ===============
echo "ğŸš€ æ„å»º Triton æ¨¡å‹ä»“åº“..."

# MNIST (ONNX)
mkdir -p $TRITON_DIR/mnist_mlp/1
cp -f $ONNX_DIR/mnist.onnx $TRITON_DIR/mnist_mlp/1/model.onnx
cat > $TRITON_DIR/mnist_mlp/config.pbtxt <<EOF
name: "mnist_mlp"
platform: "onnxruntime_onnx"
max_batch_size: 8
input [
  { name: "input", data_type: TYPE_FP32, dims: [1,28,28] }
]
output [
  { name: "output", data_type: TYPE_FP32, dims: [10] }
]
EOF

# ResNet50 (TensorRT)
mkdir -p $TRITON_DIR/resnet50/1
cp -f $TRT_DIR/resnet50_fp16.engine $TRITON_DIR/resnet50/1/model.plan
cat > $TRITON_DIR/resnet50/config.pbtxt <<EOF
name: "resnet50"
platform: "tensorrt_plan"
max_batch_size: 16
input [
  { name: "input", data_type: TYPE_FP32, dims: [3,224,224] }
]
output [
  { name: "output", data_type: TYPE_FP32, dims: [1000] }
]
EOF

echo "âœ… Triton æ¨¡å‹ä»“åº“å·²ç”Ÿæˆ: $TRITON_DIR"
```

##### ğŸ”§ ä½¿ç”¨æ–¹æ³•

1. ç¡®ä¿ `scripts/` ç›®å½•ä¸‹å·²ç»æœ‰ï¼š
   - `train_mnist.py`
   - `export_mnist.py`
   - `export_resnet50.py`
2. ç»™è„šæœ¬åŠ æ‰§è¡Œæƒé™ï¼š

```bash
chmod +x scripts/prepare_models.sh
```

3. æ‰§è¡Œï¼š

```bash
./scripts/prepare_models.sh
```

![image-20250829022659950](./report_day7.assets/image-20250829022659950.png)

å®Œæˆåï¼Œä½ ä¼šå¾—åˆ°ï¼š

![image-20250829022735658](./report_day7.assets/image-20250829022735658.png)

## 3ï¸âƒ£ éƒ¨ç½² Triton åˆ° K8s

#### 1. å‡†å¤‡é•œåƒ

ç¼–å†™ Dockerfileï¼ˆå†…ç½®æ¨¡å‹ï¼‰

`Dockerfile.triton`

```dockerfile
FROM nvcr.io/nvidia/tritonserver:23.05-py3

# æŠŠæ¨¡å‹ä»“åº“æ‹·è´åˆ°é•œåƒå†…
COPY triton/ /models/

# å¯åŠ¨ Triton æ—¶ç›´æ¥åŠ è½½ /models
CMD ["tritonserver", "--model-repository=/models"]
```

#### 2. æ„å»ºé•œåƒ

åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼š

```bash
minikube image build -t my-triton:latest -f Dockerfile.triton .
# éªŒè¯é•œåƒå·²è¿›åˆ°èŠ‚ç‚¹ï¼ˆcontainerd åœºæ™¯ï¼‰
minikube ssh -- sudo crictl images | grep my-triton
```

![image-20250829023011460](./report_day7.assets/image-20250829023011460.png)

#### 3. ç¼–å†™ K8s Deployment + Service

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: triton
  template:
    metadata:
      labels:
        app: triton
    spec:
      containers:
      - name: triton
        image: my-triton:latest   # ç”¨æˆ‘ä»¬åˆšåˆšæ„å»ºçš„é•œåƒ
        imagePullPolicy: Never
        ports:
        - containerPort: 8000   # HTTP
        - containerPort: 8001   # gRPC
        - containerPort: 8002   # Metrics
        resources:
          limits:
            nvidia.com/gpu: 1
---
apiVersion: v1
kind: Service
metadata:
  name: triton-service
spec:
  type: NodePort
  selector:
    app: triton
  ports:
  - name: http
    port: 8000
    nodePort: 30080
  - name: grpc
    port: 8001
    nodePort: 30081
  - name: metrics
    port: 8002
    nodePort: 30082
```

æ‰§è¡Œï¼š

```bash
kubectl delete -f k8s/triton-deploy.yaml
kubectl apply -f k8s/triton-deploy.yaml
# æŸ¥çœ‹ Pod & Service çŠ¶æ€
kubectl get pods
kubectl get svc
# æŸ¥çœ‹ Triton æ—¥å¿—
kubectl logs -f deploy/triton-server
```

![image-20250829023122512](./report_day7.assets/image-20250829023122512.png)

![image-20250829023159126](./report_day7.assets/image-20250829023159126.png)

âœ… æ•ˆæœï¼š

- ä¸€ä¸ª `triton-server` Pod è¿è¡Œä¸­

- `triton-service` æš´éœ²äº† NodePort (30080/30081/30082)

- è®¿é—®ï¼š

  ```bash
  curl -v http://192.168.49.2:30080/v2/health/ready
  ```

  â†’ `HTTP 200 OK` è¡¨ç¤º Triton å·²å¯åŠ¨ã€‚

  ![image-20250829023429281](./report_day7.assets/image-20250829023429281.png)

  ```bash
  curl http://192.168.49.2:30080/v2/models/mnist_mlp
  curl http://192.168.49.2:30080/v2/models/resnet50
  ```

  ![image-20250829023505644](./report_day7.assets/image-20250829023505644.png)![image-20250829023523946](./report_day7.assets/image-20250829023523946.png)

------

## 4ï¸âƒ£ éƒ¨ç½² Prometheus

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 5s
    scrape_configs:
      - job_name: 'triton'
        static_configs:
          - targets: ['triton-service:8002']
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus
        args: ["--config.file=/etc/prometheus/prometheus.yml"]
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
      volumes:
      - name: config
        configMap:
          name: prometheus-config
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus-service
spec:
  type: NodePort
  selector:
    app: prometheus
  ports:
  - port: 9090
    nodePort: 30090
```

æ‰§è¡Œï¼š

```bash
kubectl apply -f k8s/prometheus-deploy.yaml
```

âœ… æ•ˆæœï¼š

- Prometheus Pod è¿è¡Œä¸­

![image-20250829030525600](./report_day7.assets/image-20250829030525600.png)

- è®¿é—®ï¼š

  ```
  http://192.168.49.2:30090
  ```

  è¿›å…¥ **Status â†’ Targets** é¡µé¢ï¼Œç¡®è®¤ `triton-service:8002` çŠ¶æ€ä¸º `UP`ã€‚

![image-20250829031236986](./report_day7.assets/image-20250829031236986.png)

------

## 5ï¸âƒ£ éƒ¨ç½² Grafana

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana
        ports:
        - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: grafana-service
spec:
  type: NodePort
  selector:
    app: grafana
  ports:
  - port: 3000
    nodePort: 30300

```

æ‰§è¡Œï¼š

```
kubectl apply -f k8s/grafana-deploy.yaml
```

âœ… æ•ˆæœï¼š

- Grafana Pod è¿è¡Œä¸­

- è®¿é—® http://192.168.49.2:30300

- ç™»å½•è´¦å·å¯†ç ï¼š`admin/admin`

- ç™»å½•åï¼Œç‚¹å‡»å·¦ä¾§èœå• **é½¿è½®å›¾æ ‡ (âš™ï¸ Configuration)** â†’ **Data Sources**

  ç‚¹å‡» **Add data source**

  é€‰æ‹© **Prometheus**

  åœ¨ `HTTP > URL` å¡«å†™ï¼š

  ```
  http://prometheus-service:9090
  ```

- å¯¼å…¥ Dashboard â†’ å¯çœ‹åˆ° GPU/QPS/å»¶è¿Ÿå®æ—¶æ›²çº¿

------

## 6ï¸âƒ£ é…ç½®å‘Šè­¦

å®‰è£…helm

```bash
curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -
sudo apt-get install apt-transport-https --yes
echo "deb https://baltocdn.com/helm/stable/debian/ all main" | \
  sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
helm version
```

![image-20250829211958728](./report_day7.assets/image-20250829211958728.png)

å®‰è£… Prometheus Operator

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# å®‰è£… kube-prometheus-stackï¼Œä¼šåŒ…å« prometheus, grafana, alertmanager, CRDs
helm install monitoring prometheus-community/kube-prometheus-stack
```

å®‰è£…å®Œæˆåï¼ŒCRDs å°±ä¼šå­˜åœ¨ï¼Œä½ çš„ `alertmanager.yaml` å°±èƒ½æ­£å¸¸ applyã€‚

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: triton-alerts
  namespace: monitoring   # âœ… ç¡®ä¿å’Œ Prometheus Operator åœ¨åŒä¸€ namespace
  labels:
    release: monitoring-kube-prometheus   # âœ… å¯¹åº”ä½ çš„ release åç§°
spec:
  groups:
  - name: triton-alerts
    rules:
    - alert: HighLatency
      expr: avg(nv_inference_request_duration_us) / 1000 > 200
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "æ¨ç†å»¶è¿Ÿè¶…è¿‡200ms"
    - alert: HighGPUUsage
      expr: avg(nv_gpu_utilization) > 90
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "GPU åˆ©ç”¨ç‡è¿‡é«˜"
```

åº”ç”¨ï¼š

```
kubectl apply -f k8s/alertmanager.yaml
```

âœ… æ•ˆæœï¼š

- å½“æ¨ç†å»¶è¿Ÿ > 200ms æˆ– GPU åˆ©ç”¨ç‡ > 90% æ—¶ï¼ŒPrometheus è§¦å‘å‘Šè­¦ â†’ Alertmanager è½¬å‘é€šçŸ¥ï¼ˆé‚®ä»¶/Slack/Webhookï¼‰ã€‚

æŸ¥çœ‹ PrometheusRule æ˜¯å¦å­˜åœ¨ï¼š

```
kubectl get prometheusrules -n monitoring | grep triton
```

![image-20250830023355389](./report_day7.assets/image-20250830023355389.png)

æŸ¥çœ‹è§„åˆ™è¯¦æƒ…ï¼š

```
kubectl describe prometheusrule triton-alerts -n monitoring
```

![image-20250830023412021](./report_day7.assets/image-20250830023412021.png)